model: NousResearch/Llama-3.2-1B

modelParameters:
  maxModelLen: 8192

inference:
  serviceName: llama-32-1b-vllm
  serviceNamespace: default
  accelerator: gpu
  framework: vllm

  modelServer:
    image:
      repository: public.ecr.aws/deep-learning-containers/vllm
      tag: 0.11.0-gpu-py312
