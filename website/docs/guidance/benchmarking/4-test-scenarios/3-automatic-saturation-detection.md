---
sidebar_label: Scenario 3 - Automatic Saturation Detection
---

# SCENARIO 3: Automatic Saturation Detection

## When to use this scenario:
Use sweep mode for automated capacity discovery when you don't want to manually guess appropriate QPS test stagesâ€”ideal for initial deployments, CI/CD pipelines, or quick capacity re-validation after infrastructure changes. The tool floods your system to empirically determine saturation, then automatically generates intelligent test stages clustered around that critical point. This eliminates human bias in test design and ensures consistent, reproducible methodology across different environments and teams, though you trade fine-grained control for scientific automation.
**Choose Scenario 2** when you need to validate specific load targets (e.g., "can we handle 20 QPS?") or want predictable test stages for production environments.
**Choose Scenario 3** when discovering unknown capacity limits or when consistent automated methodology matters more than testing specific QPS values.

## Configuration:

```bash
cat > 03-scenario-sweep.yaml <<'EOF'
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: inference-perf-sweep
  namespace: benchmarking
data:
  config.yml: |
    api:
      type: chat
      streaming: true

    data:
      type: synthetic
      input_distribution:
        mean: 512
        std_dev: 128
        min: 128
        max: 2048
      output_distribution:
        mean: 256
        std_dev: 64
        min: 32
        max: 512

    load:
      type: constant
      stages: []  # Auto-generated by sweep
      sweep:
        type: geometric  # Stages cluster around saturation
        num_requests: 2000
        timeout: 60
        num_stages: 5
        stage_duration: 180
        saturation_percentile: 95
      num_workers: 8

    server:
      type: vllm
      model_name: mistral-7b
      base_url: http://mistral-vllm.vllm-benchmark:8000
      ignore_eos: true

    tokenizer:
      pretrained_model_name_or_path: mistralai/Mistral-7B-Instruct-v0.3

    storage:
      simple_storage_service:
        bucket_name: "inference-perf-results"
        path: "sweep-test/{timestamp}"
---
apiVersion: batch/v1
kind: Job
metadata:
  name: inference-perf-sweep
  namespace: benchmarking
  labels:
    app: inference-perf
    scenario: sweep
spec:
  backoffLimit: 2
  ttlSecondsAfterFinished: 3600
  template:
    metadata:
      labels:
        app: inference-perf
        scenario: sweep
    spec:
      restartPolicy: Never
      serviceAccountName: inference-perf-sa

      # Co-locate benchmark with inference pods for reproducible results
      affinity:
        podAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchLabels:
                app: mistral-vllm
            topologyKey: topology.kubernetes.io/zone

      containers:
      - name: inference-perf
        image: quay.io/inference-perf/inference-perf:v0.2.0
        command: ["/bin/sh", "-c"]
        args:
        - |
          echo "Installing dependencies for Mistral models..."
          pip install --no-cache-dir sentencepiece==0.2.0 protobuf==5.29.2
          echo "Dependencies installed successfully"
          echo "Starting Automatic Saturation Detection (Sweep Mode)..."
          inference-perf --config_file /workspace/config.yml
        volumeMounts:
        - name: config
          mountPath: /workspace/config.yml
          subPath: config.yml
        resources:
          requests:
            cpu: "2"
            memory: "4Gi"
          limits:
            cpu: "4"
            memory: "8Gi"

      volumes:
      - name: config
        configMap:
          name: inference-perf-sweep
EOF

kubectl apply -f 03-scenario-sweep.yaml
```

## Key Configuration:

* Variable synthetic data distributions
* Sweep mode (automatic): floods system with configurable request count (default: 2000) over 60 seconds to discover saturation point
* Streaming enabled

## Understanding the results:
The tool's preprocessing phase identifies saturation by flooding your system with 2000 requests over 60 seconds and measuring processing rate; the `saturation_percentile: 95` means it uses the 95th percentile of observed rates for conservative estimates. Review the automatically generated stages in the logs (geometric clustering produces tighter spacing near saturation, like 4, 8, 14, 17, 18 QPS) and compare the detected saturation point against your manual testing expectations. Significant discrepancies reveal queueing bottlenecks or resource constraints you might have missed, and the geometric distribution provides rich data precisely where performance transitions from stable to degraded.

Configuring the **Saturation Probe**: The `num_requests` parameter in the sweep configuration controls how many requests are sent during the initial saturation discovery phase. The default value of 2000 is appropriate for most deployments, but you can adjust this based on your expected capacity
