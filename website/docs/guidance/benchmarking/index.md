---
sidebar_label: Benchmarking LLM Inference Performance on Amazon EKS
---

# Benchmarking Guide (With Inference Perf)

## What This Guide Covers

This guide provides a comprehensive approach to benchmarking LLM inference performance:

- **[Understanding the Benchmark Challenge](./1-understanding-the-benchmark-challenge/index.md)** - Why LLM benchmarking is complex and what makes it different from traditional AI models
- **[Key Metrics for Benchmarking LLMs](./2-key-metrics-for-benchmarking-llms/index.md)** - Essential metrics (TTFT, ITL, TPS) and what they mean for your deployment
- **[Benchmarking with Inference Perf](./3-benchmarking-with-inference-perf/1-inference-perf.md)** - Using the standardized Inference Perf tool to measure performance
- **Test Scenarios** - Practical examples for baseline, saturation, production simulation, and real dataset testing
- **Resources** - Complete deployment examples and reference configurations
