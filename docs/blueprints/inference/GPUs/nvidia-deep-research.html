<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-blueprints/inference/GPUs/nvidia-deep-research" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.0">
<title data-rh="true">NVIDIA Enterprise RAG and AI-Q Research Assistant on EKS | AI on EKS</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://awslabs.github.io/ai-on-eks/docs/blueprints/inference/GPUs/nvidia-deep-research"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="NVIDIA Enterprise RAG and AI-Q Research Assistant on EKS | AI on EKS"><meta data-rh="true" name="description" content="Deployment of Enterprise RAG and AI-Q on EKS requires access to GPU instances (g5, p4, or p5 families). This blueprint relies on Karpenter autoscaling for dynamic GPU provisioning."><meta data-rh="true" property="og:description" content="Deployment of Enterprise RAG and AI-Q on EKS requires access to GPU instances (g5, p4, or p5 families). This blueprint relies on Karpenter autoscaling for dynamic GPU provisioning."><link data-rh="true" rel="icon" href="/ai-on-eks/img/header-icon.png"><link data-rh="true" rel="canonical" href="https://awslabs.github.io/ai-on-eks/docs/blueprints/inference/GPUs/nvidia-deep-research"><link data-rh="true" rel="alternate" href="https://awslabs.github.io/ai-on-eks/docs/blueprints/inference/GPUs/nvidia-deep-research" hreflang="en"><link data-rh="true" rel="alternate" href="https://awslabs.github.io/ai-on-eks/docs/blueprints/inference/GPUs/nvidia-deep-research" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Inference on EKS","item":"https://awslabs.github.io/ai-on-eks/docs/category/inference-on-eks"},{"@type":"ListItem","position":2,"name":"GPU Inference on EKS","item":"https://awslabs.github.io/ai-on-eks/docs/category/gpu-inference-on-eks"},{"@type":"ListItem","position":3,"name":"NVIDIA Enterprise RAG and AI-Q Research Assistant on EKS","item":"https://awslabs.github.io/ai-on-eks/docs/blueprints/inference/GPUs/nvidia-deep-research"}]}</script><link rel="stylesheet" href="/ai-on-eks/assets/css/styles.c270b852.css">
<script src="/ai-on-eks/assets/js/runtime~main.b917093a.js" defer="defer"></script>
<script src="/ai-on-eks/assets/js/main.870d4344.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light")),document.documentElement.setAttribute("data-theme-choice",t||"system")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}(),document.documentElement.setAttribute("data-announcement-bar-initially-dismissed",function(){try{return"true"===localStorage.getItem("docusaurus.announcement.dismiss")}catch(t){}return!1}())</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><div class="theme-announcement-bar announcementBar_mb4j" style="background-color:#667eea;color:#ffffff" role="banner"><div class="announcementBarPlaceholder_vyr4"></div><div class="content_knG7 announcementBarContent_xLdY">GenAI on EKS workshop series! <a target="_blank" rel="noopener noreferrer" href="https://aws-experience.com/emea/smb/events/series/get-hands-on-with-amazon-eks?trk=9be4af2e-2339-40ae-b5e9-57b6a7704c36&sc_channel=el" style="color: #ffffff; text-decoration: underline; font-weight: bold; margin-left: 10px;">Register now â†’</a></div><button type="button" aria-label="Close" class="clean-btn close closeButton_CVFx announcementBarClose_gvF7"><svg viewBox="0 0 15 15" width="14" height="14"><g stroke="currentColor" stroke-width="3.1"><path d="M.75.75l13.5 13.5M14.25.75L.75 14.25"></path></g></svg></button></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/ai-on-eks/"><div class="navbar__logo"><img src="/ai-on-eks/img/header-icon.png" alt="AIoEKS Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/ai-on-eks/img/header-icon.png" alt="AIoEKS Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div></a><a class="navbar__item navbar__link" href="/ai-on-eks/docs/infra">Infrastructure</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/ai-on-eks/docs/blueprints">Blueprints</a><a class="navbar__item navbar__link" href="/ai-on-eks/docs/guidance">Guidance</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/awslabs/ai-on-eks" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><div class="navbar__search"><span aria-label="expand searchbar" role="button" class="search-icon" tabindex="0"></span><input id="search_input_react" type="search" placeholder="Loading..." aria-label="Search" class="navbar__search-input search-bar" disabled=""></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG menuWithAnnouncementBar_GW3s"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ai-on-eks/docs/blueprints"><span title="Overview" class="linkLabel_WmDU">Overview</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/ai-on-eks/docs/category/training-on-eks"><span title="Training on EKS" class="categoryLinkLabel_W154">Training on EKS</span></a><button aria-label="Expand sidebar category &#x27;Training on EKS&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" href="/ai-on-eks/docs/category/inference-on-eks"><span title="Inference on EKS" class="categoryLinkLabel_W154">Inference on EKS</span></a><button aria-label="Collapse sidebar category &#x27;Inference on EKS&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" tabindex="0" href="/ai-on-eks/docs/category/gpu-inference-on-eks"><span title="GPU Inference on EKS" class="categoryLinkLabel_W154">GPU Inference on EKS</span></a><button aria-label="Collapse sidebar category &#x27;GPU Inference on EKS&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ai-on-eks/docs/blueprints/inference/GPUs/vLLM-rayserve"><span title="RayServe with vLLM" class="linkLabel_WmDU">RayServe with vLLM</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ai-on-eks/docs/blueprints/inference/GPUs/vLLM-NVIDIATritonServer"><span title="NVIDIA Triton Server with vLLM" class="linkLabel_WmDU">NVIDIA Triton Server with vLLM</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ai-on-eks/docs/blueprints/inference/GPUs/stablediffusion-gpus"><span title="Stable Diffusion on GPU" class="linkLabel_WmDU">Stable Diffusion on GPU</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ai-on-eks/docs/blueprints/inference/GPUs/nvidia-nim-llama3"><span title="NVIDIA NIM LLM on Amazon EKS" class="linkLabel_WmDU">NVIDIA NIM LLM on Amazon EKS</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ai-on-eks/docs/blueprints/inference/GPUs/nvidia-nim-operator"><span title="NVIDIA NIM Operator on EKS" class="linkLabel_WmDU">NVIDIA NIM Operator on EKS</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ai-on-eks/docs/blueprints/inference/GPUs/ray-vllm-deepseek"><span title="DeepSeek-R1 on EKS" class="linkLabel_WmDU">DeepSeek-R1 on EKS</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ai-on-eks/docs/blueprints/inference/GPUs/nvidia-dynamo"><span title="NVIDIA Dynamo on Amazon EKS" class="linkLabel_WmDU">NVIDIA Dynamo on Amazon EKS</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/ai-on-eks/docs/blueprints/inference/GPUs/nvidia-deep-research"><span title="NVIDIA Enterprise RAG and AI-Q Research Assistant on EKS" class="linkLabel_WmDU">NVIDIA Enterprise RAG and AI-Q Research Assistant on EKS</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ai-on-eks/docs/blueprints/inference/GPUs/aibrix-deepseek-distill"><span title="AIBrix on EKS" class="linkLabel_WmDU">AIBrix on EKS</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai-on-eks/docs/category/neuron-inference-on-eks"><span title="Neuron Inference on EKS" class="categoryLinkLabel_W154">Neuron Inference on EKS</span></a><button aria-label="Expand sidebar category &#x27;Neuron Inference on EKS&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai-on-eks/docs/blueprints/inference"><span title="Overview" class="linkLabel_WmDU">Overview</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai-on-eks/docs/blueprints/inference/inference-charts"><span title="Inference Charts" class="linkLabel_WmDU">Inference Charts</span></a></li></ul></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/ai-on-eks/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/ai-on-eks/docs/category/inference-on-eks"><span>Inference on EKS</span></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/ai-on-eks/docs/category/gpu-inference-on-eks"><span>GPU Inference on EKS</span></a></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">NVIDIA Enterprise RAG and AI-Q Research Assistant on EKS</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><div class="theme-admonition theme-admonition-warning admonition_xJq3 alert alert--warning"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>warning</div><div class="admonitionContent_BuS1"><p>Deployment of Enterprise RAG and AI-Q on EKS requires access to GPU instances (g5, p4, or p5 families). This blueprint relies on <a href="https://karpenter.sh/" target="_blank" rel="noopener noreferrer">Karpenter</a> autoscaling for dynamic GPU provisioning.</p></div></div>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>info</div><div class="admonitionContent_BuS1"><p>This blueprint provides two deployment options: <strong>Enterprise RAG Blueprint</strong> (multi-modal document processing with NVIDIA Nemotron and NeMo Retriever Models) or the full <strong>AI-Q Research Assistant</strong> (adds automated research reports with web search). Both run on Amazon EKS with dynamic GPU autoscaling.</p><p>Sources: <a href="https://github.com/NVIDIA-AI-Blueprints/rag" target="_blank" rel="noopener noreferrer">NVIDIA RAG Blueprint</a> | <a href="https://github.com/NVIDIA-AI-Blueprints/aiq-research-assistant" target="_blank" rel="noopener noreferrer">NVIDIA AI-Q Research Assistant</a></p></div></div>
<header><h1>NVIDIA Enterprise RAG &amp; AI-Q Research Assistant on Amazon EKS</h1></header>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="what-is-nvidia-ai-q-research-assistant">What is NVIDIA AI-Q Research Assistant?<a href="#what-is-nvidia-ai-q-research-assistant" class="hash-link" aria-label="Direct link to What is NVIDIA AI-Q Research Assistant?" title="Direct link to What is NVIDIA AI-Q Research Assistant?" translate="no">â€‹</a></h2>
<p><a href="https://build.nvidia.com/nvidia/aiq" target="_blank" rel="noopener noreferrer">NVIDIA AI-Q Research Assistant</a> is an AI-powered research assistant that creates custom AI researchers capable of operating anywhere, informed by your own data sources, synthesizing hours of research in minutes. The AI-Q NVIDIA Blueprint enables developers to connect AI agents to enterprise data and use reasoning and tools to distill in-depth source materials with efficiency and precision.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="key-capabilities">Key Capabilities<a href="#key-capabilities" class="hash-link" aria-label="Direct link to Key Capabilities" title="Direct link to Key Capabilities" translate="no">â€‹</a></h3>
<p><strong>Advanced Research Automation:</strong></p>
<ul>
<li><strong>5x faster token generation</strong> for rapid report synthesis</li>
<li><strong>15x faster data ingestion</strong> with better semantic accuracy</li>
<li>Summarize diverse data sets with efficiency and precision</li>
<li>Generate comprehensive research reports automatically</li>
</ul>
<p><strong>NVIDIA NeMo Agent Toolkit:</strong></p>
<ul>
<li>Ease development and optimization of agentic workflows</li>
<li>Unify, evaluate, audit, and debug workflows across different frameworks</li>
<li>Identify opportunities for optimization</li>
<li>Flexibly choose and connect agents and tools best suited for each task</li>
</ul>
<p><strong>Advanced Semantic Query with NVIDIA NeMo Retriever:</strong></p>
<ul>
<li>Multimodal PDF data extraction and retrieval (text, tables, charts, infographics)</li>
<li>15x faster ingestion of enterprise data</li>
<li>3x lower retrieval latency</li>
<li>Multilingual and cross-lingual support</li>
<li>Reranking to further improve accuracy</li>
<li>GPU-accelerated index creation and search</li>
</ul>
<p><strong>Fast Reasoning with Llama Nemotron:</strong></p>
<ul>
<li>Highest accuracy and lowest latency reasoning capabilities</li>
<li>Uses <a href="https://build.nvidia.com/nvidia/llama-3_3-nemotron-super-49b-v1_5" target="_blank" rel="noopener noreferrer">Llama-3.3-Nemotron-Super-49B-v1.5</a> reasoning model</li>
<li>Analyze data sources and identify patterns</li>
<li>Propose solutions based on comprehensive research</li>
<li>Context-aware generation backed by enterprise data</li>
</ul>
<p><strong>Web Search Integration:</strong></p>
<ul>
<li>Real-time web search powered by Tavily API</li>
<li>Supplements on-premise sources with current information</li>
<li>Expands research beyond internal documents</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="ai-q-components">AI-Q Components<a href="#ai-q-components" class="hash-link" aria-label="Direct link to AI-Q Components" title="Direct link to AI-Q Components" translate="no">â€‹</a></h3>
<p>Per the <a href="https://github.com/NVIDIA-AI-Blueprints/aiq-research-assistant" target="_blank" rel="noopener noreferrer">official AI-Q architecture</a>:</p>
<p><strong>1. NVIDIA AI Workbench</strong></p>
<ul>
<li>Simplified development environment for agentic workflows</li>
<li>Local testing and customization</li>
<li>Easy configuration of different LLMs</li>
<li>NVIDIA NeMo Agent Toolkit integration</li>
</ul>
<p><strong>2. NVIDIA RAG Blueprint</strong></p>
<ul>
<li>Solution for querying large sets of on-premise multi-modal documents</li>
<li>Supports text, images, tables, and charts extraction</li>
<li>Semantic search and retrieval with GPU acceleration</li>
<li>Foundation for AI-Q&#x27;s research capabilities</li>
</ul>
<p><strong>3. NVIDIA NeMo Retriever Microservices</strong></p>
<ul>
<li>Multi-modal document ingestion</li>
<li>Graphic elements detection</li>
<li>Table structure extraction</li>
<li>PaddleOCR for text recognition</li>
<li>15x faster data ingestion</li>
</ul>
<p><strong>4. NVIDIA NIM Microservices</strong></p>
<ul>
<li>Optimized inference containers for LLMs and vision models</li>
<li><a href="https://build.nvidia.com/nvidia/llama-3_3-nemotron-super-49b-v1_5" target="_blank" rel="noopener noreferrer">Llama-3.3-Nemotron-Super-49B-v1.5</a> reasoning model</li>
<li>Llama-3.3-70B-Instruct model for report generation</li>
<li>GPU-accelerated inference</li>
</ul>
<p><strong>5. Web Search (Tavily)</strong></p>
<ul>
<li>Supplements on-premise sources with real-time web search</li>
<li>Expands research beyond internal documents</li>
<li>Powers web-augmented research reports</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="what-is-nvidia-enterprise-rag-blueprint">What is NVIDIA Enterprise RAG Blueprint?<a href="#what-is-nvidia-enterprise-rag-blueprint" class="hash-link" aria-label="Direct link to What is NVIDIA Enterprise RAG Blueprint?" title="Direct link to What is NVIDIA Enterprise RAG Blueprint?" translate="no">â€‹</a></h2>
<p>The <a href="https://build.nvidia.com/nvidia/build-an-enterprise-rag-pipeline" target="_blank" rel="noopener noreferrer">NVIDIA Enterprise RAG Blueprint</a> is a production-ready reference workflow that provides a complete foundation for building scalable, customizable pipelines for both retrieval and generation. Powered by NVIDIA NeMo Retriever models and NVIDIA Llama Nemotron models, the blueprint is optimized for high accuracy, strong reasoning, and enterprise-scale throughput.</p>
<p>With built-in support for multimodal data ingestion, advanced retrieval, reranking, and reflection techniques, and seamless integration into LLM-powered workflows, it connects language models to enterprise data across text, tables, charts, audio, and infographics from millions of documentsâ€”enabling truly context-aware and generative responses.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="key-features">Key Features<a href="#key-features" class="hash-link" aria-label="Direct link to Key Features" title="Direct link to Key Features" translate="no">â€‹</a></h3>
<p><strong>Data Ingestion and Processing:</strong></p>
<ul>
<li><strong>Multimodal PDF data extraction</strong> with text, tables, charts and infographics</li>
<li><strong>Audio file ingestion</strong> support</li>
<li>Custom metadata support</li>
<li>Document summarization</li>
<li>Support for millions of documents at enterprise scale</li>
</ul>
<p><strong>Vector Database and Retrieval:</strong></p>
<ul>
<li>Multi-collection searchability across document sets</li>
<li><strong>Hybrid search</strong> with dense and sparse search</li>
<li>Reranking to further improve accuracy</li>
<li>GPU-accelerated index creation and search</li>
<li><strong>Pluggable vector database</strong> architecture:<!-- -->
<ul>
<li>ElasticSearch support</li>
<li>Milvus support</li>
<li>OpenSearch Serverless support (used in this deployment)</li>
</ul>
</li>
<li>Query decomposition for complex queries</li>
<li>Dynamic metadata filter generation</li>
</ul>
<p><strong>Multimodal and Advanced Generation:</strong></p>
<ul>
<li>Optional <strong>Vision Language Model (VLM)</strong> support in answer generation</li>
<li>Opt-in image captioning with VLMs</li>
<li>Multi-turn conversations for interactive Q&amp;A</li>
<li>Multi-session support for concurrent users</li>
<li>Improve accuracy with optional reflection</li>
</ul>
<p><strong>Governance and Safety:</strong></p>
<ul>
<li>Improve content safety with optional programmable guardrails</li>
<li>Enterprise-grade security features</li>
<li>Data privacy and compliance controls</li>
</ul>
<p><strong>Observability and Telemetry:</strong></p>
<ul>
<li>Evaluation scripts included (RAGAS framework)</li>
<li>OpenTelemetry support for distributed tracing</li>
<li>Zipkin integration for trace visualization</li>
<li>Grafana dashboards for metrics and monitoring</li>
<li>Performance profiling and optimization tools</li>
</ul>
<p><strong>Developer Features:</strong></p>
<ul>
<li>User interface included for testing and demos</li>
<li>NIM Operator support for GPU sharing using DRA</li>
<li>Native Python library support</li>
<li>OpenAI-compatible APIs for easy integration</li>
<li>Decomposable and customizable architecture</li>
<li>Plug-in system for extending functionality</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="enterprise-rag-use-cases">Enterprise RAG Use Cases<a href="#enterprise-rag-use-cases" class="hash-link" aria-label="Direct link to Enterprise RAG Use Cases" title="Direct link to Enterprise RAG Use Cases" translate="no">â€‹</a></h3>
<p>The Enterprise RAG Blueprint can be used standalone or as a component in larger systems:</p>
<ul>
<li><strong>Enterprise search</strong> across document repositories</li>
<li><strong>Knowledge assistants</strong> for organizational knowledge bases</li>
<li><strong>Generative copilots</strong> for domain-specific applications</li>
<li><strong>Vertical AI workflows</strong> customized for specific industries</li>
<li><strong>Foundational component</strong> in agentic workflows (like AI-Q Research Assistant)</li>
<li><strong>Customer support automation</strong> with context-aware responses</li>
<li><strong>Document analysis</strong> and summarization at scale</li>
</ul>
<p>Whether you&#x27;re building enterprise search, knowledge assistants, generative copilots, or vertical AI workflows, the NVIDIA AI Blueprint for RAG delivers everything needed to move from prototype to production with confidence. It can be used standalone, combined with other NVIDIA Blueprints, or integrated into an agentic workflow to support more advanced reasoning-driven applications.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="overview">Overview<a href="#overview" class="hash-link" aria-label="Direct link to Overview" title="Direct link to Overview" translate="no">â€‹</a></h2>
<p>This blueprint implements the <strong><a href="https://github.com/NVIDIA-AI-Blueprints/aiq-research-assistant" target="_blank" rel="noopener noreferrer">NVIDIA AI-Q Research Assistant</a></strong> on Amazon EKS, combining the <a href="https://github.com/NVIDIA-AI-Blueprints/rag" target="_blank" rel="noopener noreferrer">NVIDIA RAG Blueprint</a> with AI-Q components for comprehensive research capabilities.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="deployment-options">Deployment Options<a href="#deployment-options" class="hash-link" aria-label="Direct link to Deployment Options" title="Direct link to Deployment Options" translate="no">â€‹</a></h3>
<p>This blueprint supports two deployment modes based on your use case:</p>
<p><strong>Option 1: Enterprise RAG Blueprint</strong></p>
<ul>
<li>Deploy NVIDIA Enterprise RAG Blueprint with multi-modal document processing</li>
<li>Includes NeMo Retriever microservices and OpenSearch integration</li>
<li>Best for: Building custom RAG applications, document Q&amp;A systems, knowledge bases</li>
</ul>
<p><strong>Option 2: Full AI-Q Research Assistant</strong></p>
<ul>
<li>Includes everything from Option 1 plus AI-Q components</li>
<li>Adds automated research report generation with web search capabilities via Tavily API</li>
<li>Best for: Comprehensive research tasks, automated report generation, web-augmented research</li>
</ul>
<p>Both deployments include <a href="https://karpenter.sh/" target="_blank" rel="noopener noreferrer">Karpenter</a> autoscaling and enterprise security features. You can start with Option 1 and add AI-Q components later as your needs evolve.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="deployment-approach">Deployment Approach<a href="#deployment-approach" class="hash-link" aria-label="Direct link to Deployment Approach" title="Direct link to Deployment Approach" translate="no">â€‹</a></h3>
<p><strong>Why This Setup Process?</strong>
While this implementation involves multiple steps, it provides several advantages:</p>
<ul>
<li><strong>Complete Infrastructure</strong>: Automatically provisions VPC, EKS cluster, OpenSearch Serverless, and monitoring stack</li>
<li><strong>Enterprise Features</strong>: Includes security, monitoring, and scalability features</li>
<li><strong>AWS Integration</strong>: Leverages <a href="https://karpenter.sh/" target="_blank" rel="noopener noreferrer">Karpenter</a> autoscaling, EKS Pod Identity authentication, and managed AWS services</li>
<li><strong>Reproducible</strong>: Infrastructure as Code ensures consistent deployments across environments</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="key-features-1">Key Features<a href="#key-features-1" class="hash-link" aria-label="Direct link to Key Features" title="Direct link to Key Features" translate="no">â€‹</a></h3>
<p><strong>Performance Optimizations:</strong></p>
<ul>
<li><strong><a href="https://karpenter.sh/" target="_blank" rel="noopener noreferrer">Karpenter</a> Autoscaling</strong>: Dynamic GPU node provisioning based on workload demands</li>
<li><strong>Intelligent Instance Selection</strong>: Automatically chooses optimal GPU instance types (G5, P4, P5)</li>
<li><strong>Bin-Packing</strong>: Efficient GPU utilization across multiple workloads</li>
</ul>
<p><strong>Enterprise Ready:</strong></p>
<ul>
<li><strong>OpenSearch Serverless</strong>: Managed vector database with automatic scaling</li>
<li><strong>Pod Identity Authentication</strong>: EKS Pod Identity for secure AWS IAM access from pods</li>
<li><strong>Observability Stack</strong>: Prometheus, Grafana, and DCGM for GPU monitoring</li>
<li><strong>Secure Access</strong>: Kubernetes port-forwarding for controlled service access</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="architecture">Architecture<a href="#architecture" class="hash-link" aria-label="Direct link to Architecture" title="Direct link to Architecture" translate="no">â€‹</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="ai-q-research-assistant-architecture">AI-Q Research Assistant Architecture<a href="#ai-q-research-assistant-architecture" class="hash-link" aria-label="Direct link to AI-Q Research Assistant Architecture" title="Direct link to AI-Q Research Assistant Architecture" translate="no">â€‹</a></h3>
<p>The deployment uses Amazon EKS with <a href="https://karpenter.sh/" target="_blank" rel="noopener noreferrer">Karpenter</a>-based dynamic provisioning:</p>
<p><img decoding="async" loading="lazy" alt="NVIDIA AI-Q on EKS" src="/ai-on-eks/assets/images/nvidia-deep-research-arch-bcb1892391f776b7923c3f6d22def766.png" width="2161" height="1220" class="img_ev3q"></p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="enterprise-rag-blueprint-architecture">Enterprise RAG Blueprint Architecture<a href="#enterprise-rag-blueprint-architecture" class="hash-link" aria-label="Direct link to Enterprise RAG Blueprint Architecture" title="Direct link to Enterprise RAG Blueprint Architecture" translate="no">â€‹</a></h3>
<p><img decoding="async" loading="lazy" alt="RAG Pipeline with OpenSearch" src="/ai-on-eks/assets/images/nvidia-rag-opensearch-arch-5ed2b3a2d403da7d9a5758b4381282f5.png" width="2129" height="1700" class="img_ev3q"></p>
<p>The <a href="https://github.com/NVIDIA-AI-Blueprints/rag" target="_blank" rel="noopener noreferrer">RAG pipeline</a> processes documents through multiple specialized NIM microservices:</p>
<p><strong>1. Llama-3.3-Nemotron-Super-49B-v1.5</strong></p>
<ul>
<li><a href="https://build.nvidia.com/nvidia/llama-3_3-nemotron-super-49b-v1_5" target="_blank" rel="noopener noreferrer">Advanced reasoning model</a></li>
<li>Primary reasoning and generation for both RAG and report writing</li>
<li>Query rewriting and decomposition</li>
<li>Filter expression generation</li>
</ul>
<p><strong>2. Embedding &amp; Reranking</strong></p>
<ul>
<li>LLama 3.2 NV-EmbedQA: 2048-dim embeddings</li>
<li>LLama 3.2 NV-RerankQA: Relevance scoring</li>
</ul>
<p><strong>3. NV-Ingest Pipeline</strong></p>
<ul>
<li><strong>PaddleOCR</strong>: Text extraction from images</li>
<li><strong>Page Elements</strong>: Document layout understanding</li>
<li><strong>Graphic Elements</strong>: Chart and diagram detection</li>
<li><strong>Table Structure</strong>: Tabular data extraction</li>
</ul>
<p><strong>4. AI-Q Research Assistant Components</strong></p>
<ul>
<li>Llama-3.3-70B-Instruct model for report generation (optional, 2 GPUs)</li>
<li>Web search via Tavily API</li>
<li>Backend orchestration for research workflows</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="prerequisites">Prerequisites<a href="#prerequisites" class="hash-link" aria-label="Direct link to Prerequisites" title="Direct link to Prerequisites" translate="no">â€‹</a></h2>
<div class="theme-admonition theme-admonition-info admonition_xJq3 alert alert--info"><div class="admonitionHeading_Gvgb"><span class="admonitionIcon_Rf37"><svg viewBox="0 0 14 16"><path fill-rule="evenodd" d="M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"></path></svg></span>Important - Cost Information</div><div class="admonitionContent_BuS1"><p>This deployment uses GPU instances which can incur significant costs. See <a href="#cost-considerations">Cost Considerations</a> at the end of this guide for detailed cost estimates. <strong>Always clean up resources when not in use.</strong></p></div></div>
<p><strong>System Requirements</strong>: Any Linux/macOS system with AWS CLI access</p>
<p>Install the following tools:</p>
<ul>
<li><strong>AWS CLI</strong>: Configured with appropriate permissions (<a href="https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html" target="_blank" rel="noopener noreferrer">installation guide</a>)</li>
<li><strong>kubectl</strong>: Kubernetes command-line tool (<a href="https://kubernetes.io/docs/tasks/tools/install-kubectl/" target="_blank" rel="noopener noreferrer">installation guide</a>)</li>
<li><strong>helm</strong>: Kubernetes package manager (<a href="https://helm.sh/docs/intro/install/" target="_blank" rel="noopener noreferrer">installation guide</a>)</li>
<li><strong>terraform</strong>: Infrastructure as code tool (<a href="https://learn.hashicorp.com/tutorials/terraform/install-cli" target="_blank" rel="noopener noreferrer">installation guide</a>)</li>
<li><strong>git</strong>: Version control (<a href="https://git-scm.com/book/en/v2/Getting-Started-Installing-Git" target="_blank" rel="noopener noreferrer">installation guide</a>)</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="required-api-tokens">Required API Tokens<a href="#required-api-tokens" class="hash-link" aria-label="Direct link to Required API Tokens" title="Direct link to Required API Tokens" translate="no">â€‹</a></h3>
<ul>
<li><strong>NGC API Token</strong>: Required for accessing NVIDIA NIM containers and AI Foundation models<!-- -->
<ul>
<li><strong>First, sign up through one of these options</strong> (your API key will only work if you have one of these accounts):<!-- -->
<ul>
<li><strong>Option 1 - NVIDIA Developer Program</strong> (Quick Start):<!-- -->
<ul>
<li>Sign up <a href="https://build.nvidia.com/" target="_blank" rel="noopener noreferrer">here</a></li>
<li>Free account for POCs and development workloads</li>
<li>Ideal for testing and evaluation</li>
</ul>
</li>
<li><strong>Option 2 - NVIDIA AI Enterprise</strong> (Production):<!-- -->
<ul>
<li>Subscribe via <a href="https://aws.amazon.com/marketplace/pp/prodview-ozgjkov6vq3l6" target="_blank" rel="noopener noreferrer">AWS Marketplace</a></li>
<li>Enterprise license with full support and SLAs</li>
<li>Required for production deployments</li>
</ul>
</li>
</ul>
</li>
<li><strong>Then, generate your API key</strong>:<!-- -->
<ul>
<li>After signing up through Option 1 or 2, generate your API key at <a href="https://org.ngc.nvidia.com/setup/personal-keys" target="_blank" rel="noopener noreferrer">NGC Personal Keys</a></li>
<li>Keep this key handy - it will be needed at deployment time</li>
</ul>
</li>
</ul>
</li>
<li><strong><a href="https://tavily.com/" target="_blank" rel="noopener noreferrer">Tavily API Key</a></strong>: <strong>Optional for AI-Q Research Assistant</strong>
<ul>
<li>Enables web search capabilities in AI-Q</li>
<li>AI-Q can work in RAG-only mode without it</li>
<li>Not needed for Enterprise RAG only deployment</li>
<li>Create account at <a href="https://tavily.com/" target="_blank" rel="noopener noreferrer">Tavily</a></li>
<li>Generate API key from dashboard</li>
<li>Keep this key handy - it will be needed at deployment time if you want web search in AI-Q</li>
</ul>
</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="gpu-instance-access">GPU Instance Access<a href="#gpu-instance-access" class="hash-link" aria-label="Direct link to GPU Instance Access" title="Direct link to GPU Instance Access" translate="no">â€‹</a></h3>
<p>Ensure your AWS account has access to GPU instances. This blueprint supports multiple instance families through <a href="https://karpenter.sh/" target="_blank" rel="noopener noreferrer">Karpenter</a> NodePools:</p>
<p><strong>Supported GPU Instance Families:</strong></p>
<table><thead><tr><th>Instance Family</th><th>GPU Type</th><th>Performance Profile</th><th>Use Case</th></tr></thead><tbody><tr><td><strong>G5</strong> (default)</td><td>NVIDIA A10G</td><td>Cost-effective, 24GB VRAM</td><td>General workloads, development</td></tr><tr><td><strong>G6e</strong></td><td>NVIDIA L40S</td><td>Balanced, 48GB VRAM</td><td>High-memory models</td></tr><tr><td><strong>P4d/P4de</strong></td><td>NVIDIA A100</td><td>High-performance, 40/80GB VRAM</td><td>Large-scale deployments</td></tr><tr><td><strong>P5/P5e/P5en</strong></td><td>NVIDIA H100</td><td>Ultra-high performance, 80GB VRAM</td><td>Maximum performance</td></tr></tbody></table>
<blockquote>
<p><strong>Note</strong>: G5 instances are pre-configured in the Helm values to provide an accessible starting point. You can switch to P4/P5/G6e instances by editing the <code>nodeSelector</code> in the Helm values files - no infrastructure changes required.</p>
</blockquote>
<div class="collapsibleContent_q3kw"><div class="header_QCEw"><h4><span>Customizing GPU Instance Types (Optional)</span></h4><span class="icon_PckA">ðŸ‘ˆ</span></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="getting-started">Getting Started<a href="#getting-started" class="hash-link" aria-label="Direct link to Getting Started" title="Direct link to Getting Started" translate="no">â€‹</a></h2>
<p>Clone the repository to begin:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token function" style="color:#d73a49">git</span><span class="token plain"> clone https://github.com/awslabs/ai-on-eks.git</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token builtin class-name">cd</span><span class="token plain"> ai-on-eks</span><br></span></code></pre></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="deployment">Deployment<a href="#deployment" class="hash-link" aria-label="Direct link to Deployment" title="Direct link to Deployment" translate="no">â€‹</a></h2>
<p>This blueprint provides two deployment methods:</p>
<div class="collapsibleContent_q3kw"><div class="header_QCEw"><h2><span>Option A: Automated Deployment (Recommended)</span></h2><span class="icon_PckA">ðŸ‘ˆ</span></div></div>
<div class="collapsibleContent_q3kw"><div class="header_QCEw"><h2><span>Option B: Manual Deployment</span></h2><span class="icon_PckA">ðŸ‘ˆ</span></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="access-services">Access Services<a href="#access-services" class="hash-link" aria-label="Direct link to Access Services" title="Direct link to Access Services" translate="no">â€‹</a></h2>
<p>Once deployment is complete, access the services locally using port-forwarding.</p>
<div class="collapsibleContent_q3kw"><div class="header_QCEw"><h3><span>Port Forwarding Commands</span></h3><span class="icon_PckA">ðŸ‘ˆ</span></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="using-the-applications">Using the Applications<a href="#using-the-applications" class="hash-link" aria-label="Direct link to Using the Applications" title="Direct link to Using the Applications" translate="no">â€‹</a></h3>
<p><strong>RAG Frontend (<a href="http://localhost:3001" target="_blank" rel="noopener noreferrer">http://localhost:3001</a>):</strong></p>
<ul>
<li>Upload documents directly through the UI</li>
<li>Ask questions about your ingested documents</li>
<li>Test multi-turn conversations</li>
<li>View citations and sources</li>
</ul>
<p><strong>AI-Q Research Assistant (<a href="http://localhost:3000" target="_blank" rel="noopener noreferrer">http://localhost:3000</a>):</strong></p>
<ul>
<li>Define research topics and questions</li>
<li>Leverage both uploaded documents and web search</li>
<li>Generate comprehensive research reports automatically</li>
<li>Export reports in various formats</li>
</ul>
<p><strong>Ingestor API (<a href="http://localhost:8082/docs" target="_blank" rel="noopener noreferrer">http://localhost:8082/docs</a>):</strong></p>
<ul>
<li>Programmatic document ingestion</li>
<li>Batch upload capabilities</li>
<li>Collection management</li>
<li>View OpenAPI documentation</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="data-ingestion">Data Ingestion<a href="#data-ingestion" class="hash-link" aria-label="Direct link to Data Ingestion" title="Direct link to Data Ingestion" translate="no">â€‹</a></h2>
<p>After deploying RAG (and optionally AI-Q), you can ingest documents into the OpenSearch vector database.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="supported-file-types">Supported File Types<a href="#supported-file-types" class="hash-link" aria-label="Direct link to Supported File Types" title="Direct link to Supported File Types" translate="no">â€‹</a></h3>
<p>The RAG pipeline supports multi-modal document ingestion including:</p>
<ul>
<li>PDF documents</li>
<li>Text files (.txt, .md)</li>
<li>Images (.jpg, .png)</li>
<li>Office documents (.docx, .pptx)</li>
<li>HTML files</li>
</ul>
<p>The NeMo Retriever microservices will automatically extract text, tables, charts, and images from these documents.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="ingestion-methods">Ingestion Methods<a href="#ingestion-methods" class="hash-link" aria-label="Direct link to Ingestion Methods" title="Direct link to Ingestion Methods" translate="no">â€‹</a></h3>
<p>You have two options for ingesting documents:</p>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="method-1-ui-upload-testingsmall-datasets">Method 1: UI Upload (Testing/Small Datasets)<a href="#method-1-ui-upload-testingsmall-datasets" class="hash-link" aria-label="Direct link to Method 1: UI Upload (Testing/Small Datasets)" title="Direct link to Method 1: UI Upload (Testing/Small Datasets)" translate="no">â€‹</a></h4>
<p>Upload individual documents directly through the frontend interfaces:</p>
<ol>
<li><strong>RAG Frontend</strong> (<a href="http://localhost:3001" target="_blank" rel="noopener noreferrer">http://localhost:3001</a>) - Ideal for testing individual documents</li>
<li><strong>AIRA Frontend</strong> (<a href="http://localhost:3000" target="_blank" rel="noopener noreferrer">http://localhost:3000</a>) - Upload documents for research tasks</li>
</ol>
<p>This method is perfect for:</p>
<ul>
<li>Testing the RAG pipeline</li>
<li>Small document collections (&lt; 100 documents)</li>
<li>Quick experimentation</li>
<li>Ad-hoc document uploads</li>
</ul>
<h4 class="anchor anchorWithStickyNavbar_LWe7" id="method-2-s3-batch-ingestion-productionlarge-datasets">Method 2: S3 Batch Ingestion (Production/Large Datasets)<a href="#method-2-s3-batch-ingestion-productionlarge-datasets" class="hash-link" aria-label="Direct link to Method 2: S3 Batch Ingestion (Production/Large Datasets)" title="Direct link to Method 2: S3 Batch Ingestion (Production/Large Datasets)" translate="no">â€‹</a></h4>
<div class="collapsibleContent_q3kw"><div class="header_QCEw"><h4><span>S3 Batch Ingestion Commands</span></h4><span class="icon_PckA">ðŸ‘ˆ</span></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="verifying-ingestion">Verifying Ingestion<a href="#verifying-ingestion" class="hash-link" aria-label="Direct link to Verifying Ingestion" title="Direct link to Verifying Ingestion" translate="no">â€‹</a></h3>
<p>After ingestion, verify your documents are available:</p>
<ol>
<li><strong>Via RAG Frontend</strong>: Navigate to <a href="http://localhost:3001" target="_blank" rel="noopener noreferrer">http://localhost:3001</a> and ask a question about your documents</li>
<li><strong>Via Ingestor API</strong>: Check <a href="http://localhost:8082/docs" target="_blank" rel="noopener noreferrer">http://localhost:8082/docs</a> for collection statistics</li>
<li><strong>Via OpenSearch</strong>: Query the OpenSearch collection directly using the AWS Console</li>
</ol>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="observability">Observability<a href="#observability" class="hash-link" aria-label="Direct link to Observability" title="Direct link to Observability" translate="no">â€‹</a></h2>
<p>The RAG and AI-Q deployments include built-in observability tools for monitoring performance, tracing requests, and viewing metrics.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="access-monitoring-services">Access Monitoring Services<a href="#access-monitoring-services" class="hash-link" aria-label="Direct link to Access Monitoring Services" title="Direct link to Access Monitoring Services" translate="no">â€‹</a></h3>
<p><strong>Automated Approach (Recommended):</strong></p>
<p>Navigate to the blueprints directory and start port-forwarding:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token builtin class-name">cd</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">..</span><span class="token plain">/</span><span class="token punctuation" style="color:#393A34">..</span><span class="token plain">/blueprints/inference/nvidia-deep-research</span><br></span></code></pre></div></div>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">./app.sh port start observability</span><br></span></code></pre></div></div>
<p>This automatically port-forwards:</p>
<ul>
<li><strong>Zipkin</strong>: <a href="http://localhost:9411" target="_blank" rel="noopener noreferrer">http://localhost:9411</a> - RAG distributed tracing</li>
<li><strong>Grafana</strong>: <a href="http://localhost:8080" target="_blank" rel="noopener noreferrer">http://localhost:8080</a> - RAG metrics and dashboards</li>
<li><strong>Phoenix</strong>: <a href="http://localhost:6006" target="_blank" rel="noopener noreferrer">http://localhost:6006</a> - AI-Q workflow tracing (if deployed)</li>
</ul>
<p>Check status:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">./app.sh port status</span><br></span></code></pre></div></div>
<p>Stop observability port-forwards:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">./app.sh port stop observability</span><br></span></code></pre></div></div>
<div class="collapsibleContent_q3kw"><div class="header_QCEw"><h4><span>Manual kubectl Commands</span></h4><span class="icon_PckA">ðŸ‘ˆ</span></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="monitoring-uis">Monitoring UIs<a href="#monitoring-uis" class="hash-link" aria-label="Direct link to Monitoring UIs" title="Direct link to Monitoring UIs" translate="no">â€‹</a></h3>
<p>Once port-forwarding is active:</p>
<ul>
<li>
<p><strong>Zipkin UI</strong> (RAG tracing): <a href="http://localhost:9411" target="_blank" rel="noopener noreferrer">http://localhost:9411</a></p>
<ul>
<li>View end-to-end request traces</li>
<li>Analyze latency bottlenecks</li>
<li>Debug multi-service interactions</li>
</ul>
</li>
<li>
<p><strong>Grafana UI</strong> (RAG metrics): <a href="http://localhost:8080" target="_blank" rel="noopener noreferrer">http://localhost:8080</a></p>
<ul>
<li>Default credentials: admin/admin</li>
<li>Pre-built dashboards for RAG metrics</li>
<li>GPU utilization and throughput monitoring</li>
</ul>
</li>
<li>
<p><strong>Phoenix UI</strong> (AI-Q tracing): <a href="http://localhost:6006" target="_blank" rel="noopener noreferrer">http://localhost:6006</a></p>
<ul>
<li>Agent workflow visualization</li>
<li>LLM call tracing</li>
<li>Research report generation analysis</li>
</ul>
</li>
</ul>
<blockquote>
<p><strong>Note</strong>: For detailed information on using these observability tools, refer to:</p>
<ul>
<li><a href="https://github.com/NVIDIA-AI-Blueprints/rag/blob/main/docs/observability.md#view-traces-in-zipkin" target="_blank" rel="noopener noreferrer">Viewing Traces in Zipkin</a></li>
<li><a href="https://github.com/NVIDIA-AI-Blueprints/rag/blob/main/docs/observability.md#view-metrics-in-grafana" target="_blank" rel="noopener noreferrer">Viewing Metrics in Grafana Dashboard</a></li>
</ul>
</blockquote>
<blockquote>
<p><strong>Alternative</strong>: If you need to expose monitoring services publicly, you can create an Ingress resource with appropriate authentication and security controls.</p>
</blockquote>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="cleanup">Cleanup<a href="#cleanup" class="hash-link" aria-label="Direct link to Cleanup" title="Direct link to Cleanup" translate="no">â€‹</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="uninstall-applications-only">Uninstall Applications Only<a href="#uninstall-applications-only" class="hash-link" aria-label="Direct link to Uninstall Applications Only" title="Direct link to Uninstall Applications Only" translate="no">â€‹</a></h3>
<p>To remove the RAG and AI-Q applications while keeping the infrastructure:</p>
<p><strong>Using Automation Script (Recommended):</strong></p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token builtin class-name">cd</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">..</span><span class="token plain">/</span><span class="token punctuation" style="color:#393A34">..</span><span class="token plain">/blueprints/inference/nvidia-deep-research</span><br></span></code></pre></div></div>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">./app.sh cleanup</span><br></span></code></pre></div></div>
<p>The cleanup script will:</p>
<ul>
<li>Stop all port-forwarding processes</li>
<li>Uninstall AIRA and RAG Helm releases</li>
<li>Remove local port-forward PID files</li>
</ul>
<p><strong>Manual Application Cleanup:</strong></p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># Navigate to blueprints directory</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token builtin class-name">cd</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">..</span><span class="token plain">/</span><span class="token punctuation" style="color:#393A34">..</span><span class="token plain">/blueprints/inference/nvidia-deep-research</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Stop port-forwards</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">./app.sh port stop all</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Uninstall AIRA (if deployed)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">helm uninstall aira </span><span class="token parameter variable" style="color:#36acaa">-n</span><span class="token plain"> nv-aira</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Uninstall RAG</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">helm uninstall rag </span><span class="token parameter variable" style="color:#36acaa">-n</span><span class="token plain"> rag</span><br></span></code></pre></div></div>
<p><strong>(Optional) Clean up temporary files created during deployment:</strong></p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token function" style="color:#d73a49">rm</span><span class="token plain"> /tmp/.port-forward-*.pid</span><br></span></code></pre></div></div>
<blockquote>
<p><strong>Note</strong>: This only removes the applications. The EKS cluster and infrastructure will remain running. GPU nodes will be terminated by <a href="https://karpenter.sh/" target="_blank" rel="noopener noreferrer">Karpenter</a> within 5-10 minutes.</p>
</blockquote>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="clean-up-infrastructure">Clean Up Infrastructure<a href="#clean-up-infrastructure" class="hash-link" aria-label="Direct link to Clean Up Infrastructure" title="Direct link to Clean Up Infrastructure" translate="no">â€‹</a></h3>
<p>To remove the entire EKS cluster and all infrastructure components:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># Navigate to infra directory</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token builtin class-name">cd</span><span class="token plain"> </span><span class="token punctuation" style="color:#393A34">..</span><span class="token plain">/</span><span class="token punctuation" style="color:#393A34">..</span><span class="token plain">/</span><span class="token punctuation" style="color:#393A34">..</span><span class="token plain">/infra/nvidia-deep-research</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Run cleanup script</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">./cleanup.sh</span><br></span></code></pre></div></div>
<blockquote>
<p><strong>Warning</strong>: This will permanently delete:</p>
<ul>
<li>EKS cluster and all workloads</li>
<li>OpenSearch Serverless collection and data</li>
<li>VPC and networking resources</li>
<li>All associated AWS resources</li>
</ul>
<p>Backup important data before proceeding.</p>
</blockquote>
<p><strong>Duration</strong>: ~10-15 minutes for complete teardown</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="cost-considerations">Cost Considerations<a href="#cost-considerations" class="hash-link" aria-label="Direct link to Cost Considerations" title="Direct link to Cost Considerations" translate="no">â€‹</a></h2>
<div class="collapsibleContent_q3kw"><div class="header_QCEw"><h3><span>Estimated Costs for This Deployment</span></h3><span class="icon_PckA">ðŸ‘ˆ</span></div></div>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="references">References<a href="#references" class="hash-link" aria-label="Direct link to References" title="Direct link to References" translate="no">â€‹</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="official-nvidia-resources">Official NVIDIA Resources<a href="#official-nvidia-resources" class="hash-link" aria-label="Direct link to Official NVIDIA Resources" title="Direct link to Official NVIDIA Resources" translate="no">â€‹</a></h3>
<p><strong>ðŸ“š Documentation:</strong></p>
<ul>
<li><a href="https://github.com/NVIDIA-AI-Blueprints/aiq-research-assistant" target="_blank" rel="noopener noreferrer">NVIDIA AI-Q Research Assistant GitHub</a>: Official AI-Q blueprint repository</li>
<li><a href="https://build.nvidia.com/nvidia/aiq" target="_blank" rel="noopener noreferrer">NVIDIA AI-Q on AI Foundation</a>: AI-Q blueprint card and hosted version</li>
<li><a href="https://github.com/NVIDIA-AI-Blueprints/rag" target="_blank" rel="noopener noreferrer">NVIDIA RAG Blueprint</a>: Complete RAG platform documentation</li>
<li><a href="https://docs.nvidia.com/nim/" target="_blank" rel="noopener noreferrer">NVIDIA NIM Documentation</a>: NIM microservices reference</li>
<li><a href="https://www.nvidia.com/en-us/data-center/products/ai-enterprise/" target="_blank" rel="noopener noreferrer">NVIDIA AI Enterprise</a>: Enterprise AI platform</li>
</ul>
<p><strong>ðŸ¤– Models:</strong></p>
<ul>
<li><a href="https://build.nvidia.com/nvidia/llama-3_3-nemotron-super-49b-v1_5" target="_blank" rel="noopener noreferrer">Llama-3.3-Nemotron-Super-49B-v1.5</a>: Advanced reasoning model (49B parameters)</li>
<li><a href="https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct" target="_blank" rel="noopener noreferrer">Llama-3.3-70B-Instruct</a>: Instruction-following model</li>
</ul>
<p><strong>ðŸ“¦ Container Images &amp; Helm Charts:</strong></p>
<ul>
<li><a href="https://catalog.ngc.nvidia.com/" target="_blank" rel="noopener noreferrer">NVIDIA NGC Catalog</a>: Official container registry</li>
<li><a href="https://helm.ngc.nvidia.com/nvidia/blueprint/charts/nvidia-blueprint-rag" target="_blank" rel="noopener noreferrer">RAG Blueprint Helm Chart</a>: Kubernetes deployment</li>
<li><a href="https://catalog.ngc.nvidia.com/orgs/nim" target="_blank" rel="noopener noreferrer">NVIDIA NIM Containers</a>: Optimized inference containers</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="ai-on-eks-blueprint-resources">AI-on-EKS Blueprint Resources<a href="#ai-on-eks-blueprint-resources" class="hash-link" aria-label="Direct link to AI-on-EKS Blueprint Resources" title="Direct link to AI-on-EKS Blueprint Resources" translate="no">â€‹</a></h3>
<p><strong>ðŸ—ï¸ AI-on-EKS Blueprint Resources:</strong></p>
<ul>
<li><a href="https://github.com/awslabs/ai-on-eks" target="_blank" rel="noopener noreferrer">AI-on-EKS Repository</a>: Main blueprint repository</li>
<li><a href="https://github.com/awslabs/ai-on-eks/tree/main/infra/nvidia-deep-research" target="_blank" rel="noopener noreferrer">Infrastructure &amp; Deployment Code</a>: Terraform automation with Karpenter and application deployment scripts</li>
<li><a href="https://github.com/awslabs/ai-on-eks/tree/main/blueprints/inference/nvidia-deep-research" target="_blank" rel="noopener noreferrer">Usage Guide</a>: Post-deployment usage, data ingestion, and observability</li>
</ul>
<p><strong>ðŸ“– Documentation:</strong></p>
<ul>
<li><a href="https://github.com/awslabs/ai-on-eks/tree/main/infra/nvidia-deep-research/README.md" target="_blank" rel="noopener noreferrer">Infrastructure &amp; Deployment Guide</a>: Step-by-step infrastructure and application deployment</li>
<li><a href="https://github.com/awslabs/ai-on-eks/tree/main/blueprints/inference/nvidia-deep-research/README.md" target="_blank" rel="noopener noreferrer">Usage Guide</a>: Accessing services, data ingestion, monitoring</li>
<li><a href="https://github.com/awslabs/ai-on-eks/tree/main/infra/nvidia-deep-research/terraform/opensearch-serverless.tf" target="_blank" rel="noopener noreferrer">OpenSearch Integration</a>: Pod Identity authentication setup</li>
<li><a href="https://github.com/awslabs/ai-on-eks/tree/main/infra/nvidia-deep-research/terraform/custom_karpenter.tf" target="_blank" rel="noopener noreferrer">Karpenter Configuration</a>: P4/P5 GPU support</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="related-technologies">Related Technologies<a href="#related-technologies" class="hash-link" aria-label="Direct link to Related Technologies" title="Direct link to Related Technologies" translate="no">â€‹</a></h3>
<p><strong>â˜¸ï¸ Kubernetes &amp; AWS:</strong></p>
<ul>
<li><a href="https://aws.amazon.com/eks/" target="_blank" rel="noopener noreferrer">Amazon EKS</a>: Managed Kubernetes service</li>
<li><a href="https://karpenter.sh/" target="_blank" rel="noopener noreferrer">Karpenter</a>: Kubernetes node autoscaling</li>
<li><a href="https://docs.aws.amazon.com/opensearch-service/latest/developerguide/serverless.html" target="_blank" rel="noopener noreferrer">OpenSearch Serverless</a>: Managed vector database</li>
<li><a href="https://docs.aws.amazon.com/eks/latest/userguide/pod-identities.html" target="_blank" rel="noopener noreferrer">EKS Pod Identity</a>: IAM authentication for pods</li>
</ul>
<p><strong>ðŸ¤– AI/ML Tools:</strong></p>
<ul>
<li><a href="https://developer.nvidia.com/dcgm" target="_blank" rel="noopener noreferrer">NVIDIA DCGM</a>: GPU monitoring</li>
<li><a href="https://prometheus.io/" target="_blank" rel="noopener noreferrer">Prometheus</a>: Metrics collection</li>
<li><a href="https://grafana.com/" target="_blank" rel="noopener noreferrer">Grafana</a>: Visualization dashboards</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="next-steps">Next Steps<a href="#next-steps" class="hash-link" aria-label="Direct link to Next Steps" title="Direct link to Next Steps" translate="no">â€‹</a></h2>
<ol>
<li><strong>Explore Features</strong>: Test multi-modal document processing with various file types</li>
<li><strong>Scale Deployments</strong>: Configure multi-region or multi-cluster setups</li>
<li><strong>Integrate Applications</strong>: Connect your applications to the RAG API endpoints</li>
<li><strong>Monitor Performance</strong>: Use Grafana dashboards for ongoing monitoring</li>
<li><strong>Custom Models</strong>: Swap in your own fine-tuned models</li>
<li><strong>Security Hardening</strong>: Add authentication, rate limiting, and disaster recovery</li>
</ol>
<hr>
<p>This deployment provides the <a href="https://github.com/NVIDIA-AI-Blueprints/rag" target="_blank" rel="noopener noreferrer">NVIDIA Enterprise RAG Blueprint</a> and <a href="https://github.com/NVIDIA-AI-Blueprints/aiq-research-assistant" target="_blank" rel="noopener noreferrer">NVIDIA AI-Q Research Assistant</a> on Amazon EKS with enterprise-grade features including <a href="https://karpenter.sh/" target="_blank" rel="noopener noreferrer">Karpenter</a> automatic scaling, OpenSearch Serverless integration, and seamless AWS service integration.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"><a href="https://github.com/awslabs/ai-on-eks/blob/main/website/docs/blueprints/inference/GPUs/nvidia-deep-research.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/ai-on-eks/docs/blueprints/inference/GPUs/nvidia-dynamo"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">NVIDIA Dynamo on Amazon EKS</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/ai-on-eks/docs/blueprints/inference/GPUs/aibrix-deepseek-distill"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">AIBrix on EKS</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#what-is-nvidia-ai-q-research-assistant" class="table-of-contents__link toc-highlight">What is NVIDIA AI-Q Research Assistant?</a><ul><li><a href="#key-capabilities" class="table-of-contents__link toc-highlight">Key Capabilities</a></li><li><a href="#ai-q-components" class="table-of-contents__link toc-highlight">AI-Q Components</a></li></ul></li><li><a href="#what-is-nvidia-enterprise-rag-blueprint" class="table-of-contents__link toc-highlight">What is NVIDIA Enterprise RAG Blueprint?</a><ul><li><a href="#key-features" class="table-of-contents__link toc-highlight">Key Features</a></li><li><a href="#enterprise-rag-use-cases" class="table-of-contents__link toc-highlight">Enterprise RAG Use Cases</a></li></ul></li><li><a href="#overview" class="table-of-contents__link toc-highlight">Overview</a><ul><li><a href="#deployment-options" class="table-of-contents__link toc-highlight">Deployment Options</a></li><li><a href="#deployment-approach" class="table-of-contents__link toc-highlight">Deployment Approach</a></li><li><a href="#key-features-1" class="table-of-contents__link toc-highlight">Key Features</a></li></ul></li><li><a href="#architecture" class="table-of-contents__link toc-highlight">Architecture</a><ul><li><a href="#ai-q-research-assistant-architecture" class="table-of-contents__link toc-highlight">AI-Q Research Assistant Architecture</a></li><li><a href="#enterprise-rag-blueprint-architecture" class="table-of-contents__link toc-highlight">Enterprise RAG Blueprint Architecture</a></li></ul></li><li><a href="#prerequisites" class="table-of-contents__link toc-highlight">Prerequisites</a><ul><li><a href="#required-api-tokens" class="table-of-contents__link toc-highlight">Required API Tokens</a></li><li><a href="#gpu-instance-access" class="table-of-contents__link toc-highlight">GPU Instance Access</a></li></ul></li><li><a href="#getting-started" class="table-of-contents__link toc-highlight">Getting Started</a></li><li><a href="#deployment" class="table-of-contents__link toc-highlight">Deployment</a><ul><li><a href="#step-1-deploy-infrastructure" class="table-of-contents__link toc-highlight">Step 1: Deploy Infrastructure</a></li><li><a href="#step-2-setup-environment" class="table-of-contents__link toc-highlight">Step 2: Setup Environment</a></li><li><a href="#step-3-build-opensearch-images" class="table-of-contents__link toc-highlight">Step 3: Build OpenSearch Images</a></li><li><a href="#step-4-deploy-applications" class="table-of-contents__link toc-highlight">Step 4: Deploy Applications</a></li><li><a href="#step-1-deploy-infrastructure-1" class="table-of-contents__link toc-highlight">Step 1: Deploy Infrastructure</a></li><li><a href="#step-2-setup-environment-1" class="table-of-contents__link toc-highlight">Step 2: Setup Environment</a></li><li><a href="#step-3-configure-karpenter-nodepool-limits" class="table-of-contents__link toc-highlight">Step 3: Configure Karpenter NodePool Limits</a></li><li><a href="#step-4-integrate-opensearch-and-build-docker-images" class="table-of-contents__link toc-highlight">Step 4: Integrate OpenSearch and Build Docker Images</a></li><li><a href="#step-5-deploy-enterprise-rag-blueprint" class="table-of-contents__link toc-highlight">Step 5: Deploy Enterprise RAG Blueprint</a></li><li><a href="#step-6-deploy-ai-q-components" class="table-of-contents__link toc-highlight">Step 6: Deploy AI-Q Components</a></li></ul></li><li><a href="#access-services" class="table-of-contents__link toc-highlight">Access Services</a><ul><li><a href="#using-the-applications" class="table-of-contents__link toc-highlight">Using the Applications</a></li></ul></li><li><a href="#data-ingestion" class="table-of-contents__link toc-highlight">Data Ingestion</a><ul><li><a href="#supported-file-types" class="table-of-contents__link toc-highlight">Supported File Types</a></li><li><a href="#ingestion-methods" class="table-of-contents__link toc-highlight">Ingestion Methods</a></li><li><a href="#verifying-ingestion" class="table-of-contents__link toc-highlight">Verifying Ingestion</a></li></ul></li><li><a href="#observability" class="table-of-contents__link toc-highlight">Observability</a><ul><li><a href="#access-monitoring-services" class="table-of-contents__link toc-highlight">Access Monitoring Services</a></li><li><a href="#monitoring-uis" class="table-of-contents__link toc-highlight">Monitoring UIs</a></li></ul></li><li><a href="#cleanup" class="table-of-contents__link toc-highlight">Cleanup</a><ul><li><a href="#uninstall-applications-only" class="table-of-contents__link toc-highlight">Uninstall Applications Only</a></li><li><a href="#clean-up-infrastructure" class="table-of-contents__link toc-highlight">Clean Up Infrastructure</a></li></ul></li><li><a href="#cost-considerations" class="table-of-contents__link toc-highlight">Cost Considerations</a><ul><li><a href="#estimated-monthly-costs" class="table-of-contents__link toc-highlight">Estimated Monthly Costs</a></li><li><a href="#gpu-instance-cost-breakdown" class="table-of-contents__link toc-highlight">GPU Instance Cost Breakdown</a></li></ul></li><li><a href="#references" class="table-of-contents__link toc-highlight">References</a><ul><li><a href="#official-nvidia-resources" class="table-of-contents__link toc-highlight">Official NVIDIA Resources</a></li><li><a href="#ai-on-eks-blueprint-resources" class="table-of-contents__link toc-highlight">AI-on-EKS Blueprint Resources</a></li><li><a href="#related-technologies" class="table-of-contents__link toc-highlight">Related Technologies</a></li></ul></li><li><a href="#next-steps" class="table-of-contents__link toc-highlight">Next Steps</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Get Involved</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/awslabs/ai-on-eks" target="_blank" rel="noopener noreferrer" class="footer__link-item">Github<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Built with â¤ï¸ at AWS  <br> Â© 2025 Amazon.com, Inc. or its affiliates. All Rights Reserved</div></div></div></footer><script defer="" src="https://static.cloudflareinsights.com/beacon.min.js" data-cf-beacon="{&quot;token&quot;: &quot;7fbc7ab02fae4767b1af2588eba0cdf2&quot;}"></script></div>
</body>
</html>