<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-guidance/benchmarking/benchmarking-with-inference-perf/running-inference-perf-on-eks" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.0">
<title data-rh="true">Running Inference Perf on EKS | AI on EKS</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://awslabs.github.io/ai-on-eks/docs/guidance/benchmarking/benchmarking-with-inference-perf/running-inference-perf-on-eks"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Running Inference Perf on EKS | AI on EKS"><meta data-rh="true" name="description" content="Inference Perf is a GenAI inference performance benchmarking tool designed specifically for measuring LLM inference endpoint performance on Kubernetes. It runs as a Kubernetes Job and supports multiple model servers (vLLM, SGLang, TGI) with standardized metrics."><meta data-rh="true" property="og:description" content="Inference Perf is a GenAI inference performance benchmarking tool designed specifically for measuring LLM inference endpoint performance on Kubernetes. It runs as a Kubernetes Job and supports multiple model servers (vLLM, SGLang, TGI) with standardized metrics."><link data-rh="true" rel="icon" href="/ai-on-eks/img/header-icon.png"><link data-rh="true" rel="canonical" href="https://awslabs.github.io/ai-on-eks/docs/guidance/benchmarking/benchmarking-with-inference-perf/running-inference-perf-on-eks"><link data-rh="true" rel="alternate" href="https://awslabs.github.io/ai-on-eks/docs/guidance/benchmarking/benchmarking-with-inference-perf/running-inference-perf-on-eks" hreflang="en"><link data-rh="true" rel="alternate" href="https://awslabs.github.io/ai-on-eks/docs/guidance/benchmarking/benchmarking-with-inference-perf/running-inference-perf-on-eks" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Benchmarking LLM Inference Performance on Amazon EKS","item":"https://awslabs.github.io/ai-on-eks/docs/guidance/benchmarking/"},{"@type":"ListItem","position":2,"name":"Running Inference Perf on EKS","item":"https://awslabs.github.io/ai-on-eks/docs/guidance/benchmarking/benchmarking-with-inference-perf/running-inference-perf-on-eks"}]}</script><link rel="stylesheet" href="/ai-on-eks/assets/css/styles.c270b852.css">
<script src="/ai-on-eks/assets/js/runtime~main.0f0808bc.js" defer="defer"></script>
<script src="/ai-on-eks/assets/js/main.4d01a071.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light")),document.documentElement.setAttribute("data-theme-choice",t||"system")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}(),document.documentElement.setAttribute("data-announcement-bar-initially-dismissed",function(){try{return"true"===localStorage.getItem("docusaurus.announcement.dismiss")}catch(t){}return!1}())</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><div class="theme-announcement-bar announcementBar_mb4j" style="background-color:#667eea;color:#ffffff" role="banner"><div class="announcementBarPlaceholder_vyr4"></div><div class="content_knG7 announcementBarContent_xLdY">GenAI on EKS workshop series! <a target="_blank" rel="noopener noreferrer" href="https://aws-experience.com/emea/smb/events/series/get-hands-on-with-amazon-eks?trk=9be4af2e-2339-40ae-b5e9-57b6a7704c36&sc_channel=el" style="color: #ffffff; text-decoration: underline; font-weight: bold; margin-left: 10px;">Register now →</a></div><button type="button" aria-label="Close" class="clean-btn close closeButton_CVFx announcementBarClose_gvF7"><svg viewBox="0 0 15 15" width="14" height="14"><g stroke="currentColor" stroke-width="3.1"><path d="M.75.75l13.5 13.5M14.25.75L.75 14.25"></path></g></svg></button></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/ai-on-eks/"><div class="navbar__logo"><img src="/ai-on-eks/img/header-icon.png" alt="AIoEKS Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/ai-on-eks/img/header-icon.png" alt="AIoEKS Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div></a><a class="navbar__item navbar__link" href="/ai-on-eks/docs/infra">Infrastructure</a><a class="navbar__item navbar__link" href="/ai-on-eks/docs/blueprints">Blueprints</a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/ai-on-eks/docs/guidance">Guidance</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/awslabs/ai-on-eks" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"><div class="navbar__search"><span aria-label="expand searchbar" role="button" class="search-icon" tabindex="0"></span><input id="search_input_react" type="search" placeholder="Loading..." aria-label="Search" class="navbar__search-input search-bar" disabled=""></div></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG menuWithAnnouncementBar_GW3s"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ai-on-eks/docs/guidance"><span title="Guidance for AI workloads" class="linkLabel_WmDU">Guidance for AI workloads</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ai-on-eks/docs/guidance/eks-best-practices"><span title="EKS Best Practices" class="linkLabel_WmDU">EKS Best Practices</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--active" href="/ai-on-eks/docs/guidance/benchmarking"><span title="Benchmarking LLM Inference Performance on Amazon EKS" class="categoryLinkLabel_W154">Benchmarking LLM Inference Performance on Amazon EKS</span></a><button aria-label="Collapse sidebar category &#x27;Benchmarking LLM Inference Performance on Amazon EKS&#x27;" aria-expanded="true" type="button" class="clean-btn menu__caret"></button></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai-on-eks/docs/guidance/benchmarking/understanding-the-benchmark-challenge"><span title="Understanding the Benchmark Challenge" class="linkLabel_WmDU">Understanding the Benchmark Challenge</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai-on-eks/docs/guidance/benchmarking/key-metrics-for-benchmarking-llms"><span title="Key Metrics for Benchmarking LLMs" class="linkLabel_WmDU">Key Metrics for Benchmarking LLMs</span></a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" tabindex="0" href="/ai-on-eks/docs/guidance/benchmarking/benchmarking-with-inference-perf/inference-perf"><span title="benchmarking-with-inference-perf" class="categoryLinkLabel_W154">benchmarking-with-inference-perf</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ai-on-eks/docs/guidance/benchmarking/benchmarking-with-inference-perf/inference-perf"><span title="Benchmarking with Inference Perf" class="linkLabel_WmDU">Benchmarking with Inference Perf</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/ai-on-eks/docs/guidance/benchmarking/benchmarking-with-inference-perf/running-inference-perf-on-eks"><span title="Running Inference Perf on EKS" class="linkLabel_WmDU">Running Inference Perf on EKS</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/ai-on-eks/docs/guidance/benchmarking/benchmarking-with-inference-perf/complete-deployment-example-guide"><span title="Complete Deployment Example" class="linkLabel_WmDU">Complete Deployment Example</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" tabindex="0" href="/ai-on-eks/docs/guidance/benchmarking/test-scenarios"><span title="Test Scenarios" class="categoryLinkLabel_W154">Test Scenarios</span></a><button aria-label="Expand sidebar category &#x27;Test Scenarios&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/ai-on-eks/docs/guidance/benchmarking/resources"><span title="Resources" class="linkLabel_WmDU">Resources</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/ai-on-eks/docs/guidance/container-startup-time"><span title="Solving cold start challenges for AI/ML inference applications on Amazon EKS" class="categoryLinkLabel_W154">Solving cold start challenges for AI/ML inference applications on Amazon EKS</span></a><button aria-label="Expand sidebar category &#x27;Solving cold start challenges for AI/ML inference applications on Amazon EKS&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ai-on-eks/docs/guidance/dynamic-resource-allocation"><span title="Dynamic Resource Allocation on EKS" class="linkLabel_WmDU">Dynamic Resource Allocation on EKS</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ai-on-eks/docs/guidance/networking"><span title="Networking for AI" class="linkLabel_WmDU">Networking for AI</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/ai-on-eks/docs/guidance/observability"><span title="Observability" class="linkLabel_WmDU">Observability</span></a></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/ai-on-eks/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><a class="breadcrumbs__link" href="/ai-on-eks/docs/guidance/benchmarking"><span>Benchmarking LLM Inference Performance on Amazon EKS</span></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">benchmarking-with-inference-perf</span></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Running Inference Perf on EKS</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Running Inference Perf on EKS</h1></header>
<p>Inference Perf is a GenAI inference performance benchmarking tool designed specifically for measuring LLM inference endpoint performance on Kubernetes. It runs as a Kubernetes Job and supports multiple model servers (<a href="https://github.com/vllm-project/vllm" target="_blank" rel="noopener noreferrer">vLLM</a>, <a href="https://github.com/sgl-project/sglang" target="_blank" rel="noopener noreferrer">SGLang</a>, <a href="https://github.com/huggingface/text-generation-inference" target="_blank" rel="noopener noreferrer">TGI</a>) with standardized metrics.</p>
<p>Why use a <a href="https://kubernetes.io/docs/concepts/workloads/controllers/job/" target="_blank" rel="noopener noreferrer">Job</a>? Jobs run once and terminate when complete, making them ideal for benchmarking tasks. Results are stored locally or in cloud storage (<a href="https://aws.amazon.com/s3/" target="_blank" rel="noopener noreferrer">S3</a>).</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="prerequisites">Prerequisites<a href="#prerequisites" class="hash-link" aria-label="Direct link to Prerequisites" title="Direct link to Prerequisites" translate="no">​</a></h2>
<ul>
<li>Kubernetes cluster with kubectl access (version 1.21+)</li>
<li>A deployed inference endpoint with OpenAI-compatible API (vLLM, SGLang, TGI, or compatible)</li>
<li>Namespace for running benchmarks</li>
<li>Container image: quay.io/inference-perf/inference-perf<!-- -->:v0<!-- -->.2.0</li>
<li>(Optional) HuggingFace token for downloading tokenizers</li>
<li>(Optional) AWS credentials for S3 storage</li>
</ul>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="model-specific-dependencies">Model-Specific Dependencies<a href="#model-specific-dependencies" class="hash-link" aria-label="Direct link to Model-Specific Dependencies" title="Direct link to Model-Specific Dependencies" translate="no">​</a></h2>
<p>⚠️ IMPORTANT: Different models require different tokenizer packages:</p>
<table><thead><tr><th>Model Family</th><th>Requires sentencepiece?</th><th>Examples</th></tr></thead><tbody><tr><td>Mistral (all versions)</td><td>✅ YES</td><td>mistralai/Mistral-7B-Instruct-v0.3</td></tr><tr><td>Llama 2</td><td>✅ YES</td><td>meta-llama/Llama-2-7b-hf</td></tr><tr><td>Llama 3.1</td><td>✅ YES</td><td>meta-llama/Meta-Llama-3.1-8B</td></tr><tr><td>SmolLM2</td><td>❌ NO</td><td>HuggingFaceTB/SmolLM2-135M-Instruct</td></tr><tr><td>GPT models</td><td>❌ NO</td><td>Various GPT variants</td></tr></tbody></table>
<p>If using Mistral or Llama models, you must install the sentencepiece package. See &quot;Handling Model Dependencies&quot; section below for implementation.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="understanding-the-inference-benchmark-framework-architecture">Understanding the Inference Benchmark Framework architecture<a href="#understanding-the-inference-benchmark-framework-architecture" class="hash-link" aria-label="Direct link to Understanding the Inference Benchmark Framework architecture" title="Direct link to Understanding the Inference Benchmark Framework architecture" translate="no">​</a></h2>
<p>Before deploying, it&#x27;s important to understand the key configuration components that define your benchmark test.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="api-configuration">API Configuration<a href="#api-configuration" class="hash-link" aria-label="Direct link to API Configuration" title="Direct link to API Configuration" translate="no">​</a></h3>
<p>Defines how the tool communicates with your inference endpoint. You&#x27;ll specify whether you&#x27;re using completion or chat API, and whether streaming is enabled (required for measuring TTFT and ITL metrics).</p>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token key atrule" style="color:#00a4db">api</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">type</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> completion </span><span class="token comment" style="color:#999988;font-style:italic"># completion or chat</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">streaming</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token boolean important" style="color:#36acaa">true</span><span class="token plain"> </span><span class="token comment" style="color:#999988;font-style:italic"># Enable for TTFT/ITL metrics</span><br></span></code></pre></div></div>
<p><strong>Determining the Correct API Type:</strong></p>
<p>The inference-charts deployment automatically configures API endpoints based on the model&#x27;s capabilities. To identify which endpoints are available:</p>
<p><strong>Method 1: Check vLLM Deployment Logs (Recommended)</strong></p>
<p>Check your vLLM server logs to see which API endpoints were enabled at startup:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># View vLLM startup logs showing enabled endpoints</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl logs </span><span class="token parameter variable" style="color:#36acaa">-n</span><span class="token plain"> default </span><span class="token parameter variable" style="color:#36acaa">-l</span><span class="token plain"> app.kubernetes.io/name</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">inference-charts </span><span class="token parameter variable" style="color:#36acaa">--tail</span><span class="token operator" style="color:#393A34">=</span><span class="token number" style="color:#36acaa">100</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">|</span><span class="token plain"> </span><span class="token function" style="color:#d73a49">grep</span><span class="token plain"> </span><span class="token parameter variable" style="color:#36acaa">-i</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;route\|endpoint\|application&quot;</span><br></span></code></pre></div></div>
<p>Look for output indicating enabled routes:</p>
<ul>
<li><code>Route: /v1/completions</code> → Use <code>type: completion</code></li>
<li><code>Route: /v1/chat/completions</code> → Use <code>type: chat</code></li>
</ul>
<p>If both routes appear, use <code>completion</code> (simpler for benchmarking).</p>
<p><strong>Method 2: Check Model Capabilities (Optional)</strong></p>
<p>For understanding the model&#x27;s theoretical capabilities, review the Hugging Face model card for your model. Models with a defined chat template typically support the chat completion API, but the actual deployment configuration determines what&#x27;s enabled.</p>
<p><strong>Note:</strong> The OpenAI completion API (<code>v1/completions</code>) is deprecated by OpenAI but remains widely supported by vLLM, SGLang, and TGI. Most inference-charts deployments enable it by default without additional configuration.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="data-generation">Data Generation<a href="#data-generation" class="hash-link" aria-label="Direct link to Data Generation" title="Direct link to Data Generation" translate="no">​</a></h3>
<p>Controls what data is sent to your inference endpoint. You can use real datasets (ShareGPT) or synthetic data with controlled distributions. Synthetic data is useful when you need specific input/output length patterns for testing.</p>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token key atrule" style="color:#00a4db">data</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">type</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> synthetic </span><span class="token comment" style="color:#999988;font-style:italic"># shareGPT, synthetic, random, shared_prefix, etc.</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">input_distribution</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">mean</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">512</span><span class="token plain">      </span><span class="token comment" style="color:#999988;font-style:italic"># Average input prompt length in tokens</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">std_dev</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">128</span><span class="token plain">   </span><span class="token comment" style="color:#999988;font-style:italic"># Variation in prompt length (68% within ±128 tokens of mean)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">min</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">128</span><span class="token plain">       </span><span class="token comment" style="color:#999988;font-style:italic"># Minimum input tokens (clips distribution lower bound)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">max</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">2048</span><span class="token plain">      </span><span class="token comment" style="color:#999988;font-style:italic"># Maximum input tokens (clips distribution upper bound)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">output_distribution</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">mean</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">256</span><span class="token plain">      </span><span class="token comment" style="color:#999988;font-style:italic"># Average generated response length in tokens</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">std_dev</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">64</span><span class="token plain">    </span><span class="token comment" style="color:#999988;font-style:italic"># Variation in response length (68% within ±64 tokens of mean)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">min</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">32</span><span class="token plain">        </span><span class="token comment" style="color:#999988;font-style:italic"># Minimum output tokens (clips distribution lower bound)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">max</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">512</span><span class="token plain">       </span><span class="token comment" style="color:#999988;font-style:italic"># Maximum output tokens (clips distribution upper bound)</span><br></span></code></pre></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="load-generation">Load Generation<a href="#load-generation" class="hash-link" aria-label="Direct link to Load Generation" title="Direct link to Load Generation" translate="no">​</a></h3>
<p>Defines your load pattern - how many requests per second and for how long. You can use multiple stages to test different load levels, or use sweep mode for automatic saturation detection.</p>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token key atrule" style="color:#00a4db">load</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">type</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> constant              </span><span class="token comment" style="color:#999988;font-style:italic"># Use &#x27;constant&#x27; for uniform arrival (predictable load) or &#x27;poisson&#x27; for bursty traffic (realistic production)</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">stages</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">rate</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">10</span><span class="token plain">                </span><span class="token comment" style="color:#999988;font-style:italic"># Requests per second (QPS) - increase to test higher throughput, decrease for baseline/minimal load</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">duration</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">300</span><span class="token plain">           </span><span class="token comment" style="color:#999988;font-style:italic"># How long to sustain this rate in seconds - longer durations (300-600s) ensure stable measurements</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">num_workers</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">4</span><span class="token plain">              </span><span class="token comment" style="color:#999988;font-style:italic"># Concurrent workers generating load - increase if inference-perf can&#x27;t achieve target rate (check scheduling delay in results)</span><br></span></code></pre></div></div>
<p><strong>Note on num_workers:</strong> This controls the benchmark tool&#x27;s internal parallelism, not concurrent users. The default value of 4 works for most scenarios. Only increase if results show high <code>schedule_delay</code> (&gt; 10ms), indicating the tool cannot maintain the target rate.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="server-configuration">Server Configuration<a href="#server-configuration" class="hash-link" aria-label="Direct link to Server Configuration" title="Direct link to Server Configuration" translate="no">​</a></h3>
<p>Specifies your inference endpoint details - server type, model name, and URL.</p>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token key atrule" style="color:#00a4db">server</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">type</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> vllm </span><span class="token comment" style="color:#999988;font-style:italic"># vllm, sglang, or tgi</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">model_name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> qwen3</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">8b</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">base_url</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> http</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">//qwen3</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">vllm.default</span><span class="token punctuation" style="color:#393A34">:</span><span class="token number" style="color:#36acaa">8000</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">ignore_eos</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token boolean important" style="color:#36acaa">true</span><br></span></code></pre></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="storage-configuration">Storage Configuration<a href="#storage-configuration" class="hash-link" aria-label="Direct link to Storage Configuration" title="Direct link to Storage Configuration" translate="no">​</a></h3>
<p>Determines where benchmark results are saved. Local storage saves to the pod filesystem (requires manual copy), while S3 storage automatically persists results to your AWS bucket.</p>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token key atrule" style="color:#00a4db">storage</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">local_storage</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token comment" style="color:#999988;font-style:italic"># Default: saves in pod</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">path</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;reports-results&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic"># ⚠️ Warning: local_storage results are lost when pod terminates</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic"># To retrieve results, add &#x27;&amp;&amp; sleep infinity&#x27; to the Job args and use:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic"># kubectl cp &lt;pod-name&gt;:/workspace/reports-* ./local-results -n benchmarking</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token comment" style="color:#999988;font-style:italic"># OR</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">simple_storage_service</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token comment" style="color:#999988;font-style:italic"># S3: automatic persistence</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">bucket_name</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;my-results-bucket&quot;</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">path</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token string" style="color:#e3116c">&quot;inference-perf/results&quot;</span><br></span></code></pre></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="metrics-collection-optional">Metrics Collection (Optional)<a href="#metrics-collection-optional" class="hash-link" aria-label="Direct link to Metrics Collection (Optional)" title="Direct link to Metrics Collection (Optional)" translate="no">​</a></h3>
<p>Enables advanced metrics collection from Prometheus if your inference server exposes metrics.</p>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token key atrule" style="color:#00a4db">metrics</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">type</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> prometheus</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">prometheus</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">url</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> http</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain">//kube</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">prometheus</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">stack</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">prometheus.monitoring</span><span class="token punctuation" style="color:#393A34">:</span><span class="token number" style="color:#36acaa">9090</span><span class="token plain"> </span><span class="token comment" style="color:#999988;font-style:italic"># For ai-on-eks Path A; adjust service name/namespace for custom Prometheus</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">scrape_interval</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> </span><span class="token number" style="color:#36acaa">15</span><br></span></code></pre></div></div>
<p><strong>Note:</strong> The Prometheus URL uses Kubernetes DNS format: <code>http://&lt;service-name&gt;.&lt;namespace&gt;:&lt;port&gt;</code>. If your Prometheus is deployed in a different namespace (e.g., <code>monitoring</code>, <code>observability</code>), update the URL accordingly. The benchmark Job runs in the <code>benchmarking</code> namespace, so cross-namespace service access must be specified.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="infrastructure-topology-for-reproducible-results">Infrastructure Topology for Reproducible Results<a href="#infrastructure-topology-for-reproducible-results" class="hash-link" aria-label="Direct link to Infrastructure Topology for Reproducible Results" title="Direct link to Infrastructure Topology for Reproducible Results" translate="no">​</a></h2>
<p>For accurate, comparable benchmarks across multiple runs, the inference-perf Job <strong>MUST</strong> be placed in the same AZ as your inference deployment.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="why-this-matters">Why This Matters:<a href="#why-this-matters" class="hash-link" aria-label="Direct link to Why This Matters:" title="Direct link to Why This Matters:" translate="no">​</a></h3>
<p>Without proper placement, benchmark results become unreliable:</p>
<ul>
<li>Cross-AZ network latency adds 1-2ms per request</li>
<li>Results vary unpredictably across benchmark runs</li>
<li>You cannot determine if performance changes are real or due to infrastructure placement</li>
<li>Optimization decisions become impossible</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="example-of-the-problem">Example of the Problem:<a href="#example-of-the-problem" class="hash-link" aria-label="Direct link to Example of the Problem:" title="Direct link to Example of the Problem:" translate="no">​</a></h3>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">First benchmark run:</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Benchmark pod in us-west-2a → Inference pod in us-west-2a</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Result: TTFT = 800ms</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">Second benchmark run (after pod restart):</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Benchmark pod in us-west-2b → Inference pod in us-west-2a</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">- Result: TTFT = 850ms</span><br></span></code></pre></div></div>
<p>The 50ms difference is cross-AZ latency, not actual performance change.</p>
<p><strong>Note on Cross-AZ Testing:</strong> While same-AZ placement is recommended for baseline benchmarking and performance optimization, cross-AZ testing is valuable for validating high-availability (HA) deployments where your inference service spans multiple availability zones. If your production deployment uses multi-AZ load balancing for fault tolerance, conduct separate benchmarks with cross-AZ placement to understand the latency impact users may experience during zone-specific routing.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="required-configuration">Required Configuration:<a href="#required-configuration" class="hash-link" aria-label="Direct link to Required Configuration:" title="Direct link to Required Configuration:" translate="no">​</a></h3>
<p>All benchmark Job examples in this guide include <code>affinity</code> configuration to enforce same-AZ placement using the standard Kubernetes topology label <code>topology.kubernetes.io/zone</code>:</p>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token key atrule" style="color:#00a4db">spec</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">template</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">spec</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">affinity</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">podAffinity</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          </span><span class="token key atrule" style="color:#00a4db">requiredDuringSchedulingIgnoredDuringExecution</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          </span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain"> </span><span class="token key atrule" style="color:#00a4db">labelSelector</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">              </span><span class="token key atrule" style="color:#00a4db">matchLabels</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                </span><span class="token key atrule" style="color:#00a4db">app.kubernetes.io/component</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> qwen3</span><span class="token punctuation" style="color:#393A34">-</span><span class="token plain">vllm</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">            </span><span class="token key atrule" style="color:#00a4db">topologyKey</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> topology.kubernetes.io/zone</span><br></span></code></pre></div></div>
<p><strong>IMPORTANT:</strong> The <code>matchLabels</code> must match your actual vLLM deployment labels. Check your deployment&#x27;s pod labels with:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">kubectl get deployment qwen3-vllm </span><span class="token parameter variable" style="color:#36acaa">-n</span><span class="token plain"> default </span><span class="token parameter variable" style="color:#36acaa">-o</span><span class="token plain"> </span><span class="token assign-left variable" style="color:#36acaa">jsonpath</span><span class="token operator" style="color:#393A34">=</span><span class="token string" style="color:#e3116c">&#x27;{.spec.template.metadata.labels}&#x27;</span><span class="token plain"> </span><span class="token operator" style="color:#393A34">&amp;&amp;</span><span class="token plain"> </span><span class="token builtin class-name">echo</span><br></span></code></pre></div></div>
<p>Common label patterns:</p>
<ul>
<li>Standard deployments: <code>app: &lt;service-name&gt;</code> (simple pattern)</li>
<li>inference-charts deployments: <code>app.kubernetes.io/component: &lt;service-name&gt;</code> (used in this guide&#x27;s examples)</li>
<li>Other Helm charts: <code>app.kubernetes.io/name: &lt;service-name&gt;</code></li>
</ul>
<p>Update the <code>matchLabels</code> section in the examples to match your deployment&#x27;s actual pod labels.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="verification">Verification:<a href="#verification" class="hash-link" aria-label="Direct link to Verification:" title="Direct link to Verification:" translate="no">​</a></h3>
<p>After deploying, confirm both pods are in the same AZ:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token comment" style="color:#999988;font-style:italic"># Check both pods - they should show the same zone</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl get pods </span><span class="token parameter variable" style="color:#36acaa">-n</span><span class="token plain"> default </span><span class="token parameter variable" style="color:#36acaa">-o</span><span class="token plain"> wide </span><span class="token parameter variable" style="color:#36acaa">-l</span><span class="token plain"> app.kubernetes.io/component</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">qwen3-vllm</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">kubectl get pods </span><span class="token parameter variable" style="color:#36acaa">-n</span><span class="token plain"> benchmarking </span><span class="token parameter variable" style="color:#36acaa">-o</span><span class="token plain"> wide </span><span class="token parameter variable" style="color:#36acaa">-l</span><span class="token plain"> </span><span class="token assign-left variable" style="color:#36acaa">app</span><span class="token operator" style="color:#393A34">=</span><span class="token plain">inference-perf</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># Expected output - both in same zone:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># qwen3-vllm-xxx      ip-10-0-1-100.us-west-2a...</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain"></span><span class="token comment" style="color:#999988;font-style:italic"># inference-perf-yyy  ip-10-0-1-200.us-west-2a...</span><br></span></code></pre></div></div>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="optional-instance-type-consistency">Optional: Instance Type Consistency<a href="#optional-instance-type-consistency" class="hash-link" aria-label="Direct link to Optional: Instance Type Consistency" title="Direct link to Optional: Instance Type Consistency" translate="no">​</a></h3>
<p><strong>Instance Sizing for Benchmark Pods</strong></p>
<p>The benchmark pod runs on a separate CPU node from your GPU-based inference deployment. The m6i.2xlarge instance type (8 vCPU, 32 GB RAM) provides sufficient capacity for load generation without competing for GPU node resources.</p>
<p><strong>Important:</strong> The pod affinity configuration (<code>topology.kubernetes.io/zone</code>) ensures both pods are in the same availability zone for network consistency, NOT on the same physical node. Your cluster must have capacity for both:</p>
<ul>
<li>GPU nodes for inference (e.g., g5.2xlarge for models like Qwen3-8B)</li>
<li>CPU nodes for benchmarking (e.g., m6i.2xlarge)</li>
</ul>
<p>If using Karpenter, it will automatically provision the appropriate node types in the same AZ.</p>
<p>For maximum reproducibility (baseline benchmarks, CI/CD pipelines), you can specify the instance type:</p>
<div class="language-yaml codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-yaml codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token key atrule" style="color:#00a4db">spec</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  </span><span class="token key atrule" style="color:#00a4db">template</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    </span><span class="token key atrule" style="color:#00a4db">spec</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">nodeSelector</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">node.kubernetes.io/instance-type</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"> m6i.2xlarge</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">      </span><span class="token key atrule" style="color:#00a4db">affinity</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">        </span><span class="token key atrule" style="color:#00a4db">podAffinity</span><span class="token punctuation" style="color:#393A34">:</span><span class="token plain"></span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">          </span><span class="token comment" style="color:#999988;font-style:italic"># ... same as above</span><br></span></code></pre></div></div>
<p><strong>When to use instance type selectors:</strong></p>
<ul>
<li>Creating benchmark baselines for documentation</li>
<li>CI/CD pipelines requiring consistent results</li>
<li>Preventing Karpenter from provisioning different instance families</li>
</ul>
<p><strong>When NOT needed:</strong></p>
<ul>
<li>Homogeneous CPU node pools</li>
<li>Comparative testing (before/after on same infrastructure)</li>
</ul>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="troubleshooting">Troubleshooting:<a href="#troubleshooting" class="hash-link" aria-label="Direct link to Troubleshooting:" title="Direct link to Troubleshooting:" translate="no">​</a></h3>
<p>If your benchmark Job stays in <code>Pending</code>:</p>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">kubectl describe pod </span><span class="token parameter variable" style="color:#36acaa">-n</span><span class="token plain"> benchmarking </span><span class="token operator" style="color:#393A34">&lt;</span><span class="token plain">pod-name</span><span class="token operator" style="color:#393A34">&gt;</span><br></span></code></pre></div></div>
<p>Common issues:</p>
<ul>
<li><strong>No capacity in target AZ</strong>: Scale cluster or use <code>preferredDuringSchedulingIgnoredDuringExecution</code></li>
<li><strong>Label mismatch</strong>: Verify deployment labels match podAffinity selector</li>
</ul></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"><a href="https://github.com/awslabs/ai-on-eks/blob/main/website/docs/guidance/benchmarking/3-benchmarking-with-inference-perf/2-running-inference-perf-on-eks.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/ai-on-eks/docs/guidance/benchmarking/benchmarking-with-inference-perf/inference-perf"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Benchmarking with Inference Perf</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/ai-on-eks/docs/guidance/benchmarking/benchmarking-with-inference-perf/complete-deployment-example-guide"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Complete Deployment Example</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#prerequisites" class="table-of-contents__link toc-highlight">Prerequisites</a></li><li><a href="#model-specific-dependencies" class="table-of-contents__link toc-highlight">Model-Specific Dependencies</a></li><li><a href="#understanding-the-inference-benchmark-framework-architecture" class="table-of-contents__link toc-highlight">Understanding the Inference Benchmark Framework architecture</a><ul><li><a href="#api-configuration" class="table-of-contents__link toc-highlight">API Configuration</a></li><li><a href="#data-generation" class="table-of-contents__link toc-highlight">Data Generation</a></li><li><a href="#load-generation" class="table-of-contents__link toc-highlight">Load Generation</a></li><li><a href="#server-configuration" class="table-of-contents__link toc-highlight">Server Configuration</a></li><li><a href="#storage-configuration" class="table-of-contents__link toc-highlight">Storage Configuration</a></li><li><a href="#metrics-collection-optional" class="table-of-contents__link toc-highlight">Metrics Collection (Optional)</a></li></ul></li><li><a href="#infrastructure-topology-for-reproducible-results" class="table-of-contents__link toc-highlight">Infrastructure Topology for Reproducible Results</a><ul><li><a href="#why-this-matters" class="table-of-contents__link toc-highlight">Why This Matters:</a></li><li><a href="#example-of-the-problem" class="table-of-contents__link toc-highlight">Example of the Problem:</a></li><li><a href="#required-configuration" class="table-of-contents__link toc-highlight">Required Configuration:</a></li><li><a href="#verification" class="table-of-contents__link toc-highlight">Verification:</a></li><li><a href="#optional-instance-type-consistency" class="table-of-contents__link toc-highlight">Optional: Instance Type Consistency</a></li><li><a href="#troubleshooting" class="table-of-contents__link toc-highlight">Troubleshooting:</a></li></ul></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Get Involved</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/awslabs/ai-on-eks" target="_blank" rel="noopener noreferrer" class="footer__link-item">Github<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Built with ❤️ at AWS  <br> © 2025 Amazon.com, Inc. or its affiliates. All Rights Reserved</div></div></div></footer><script defer="" src="https://static.cloudflareinsights.com/beacon.min.js" data-cf-beacon="{&quot;token&quot;: &quot;7fbc7ab02fae4767b1af2588eba0cdf2&quot;}"></script></div>
</body>
</html>