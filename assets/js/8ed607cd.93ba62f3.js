"use strict";(self.webpackChunkdoeks_website=self.webpackChunkdoeks_website||[]).push([[2134],{28453:(e,n,t)=>{t.d(n,{R:()=>r,x:()=>o});var i=t(96540);const a={},s=i.createContext(a);function r(e){const n=i.useContext(s);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:r(e.components),i.createElement(s.Provider,{value:n},e.children)}},81547:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>c,contentTitle:()=>o,default:()=>u,frontMatter:()=>r,metadata:()=>i,toc:()=>l});const i=JSON.parse('{"id":"guidance/benchmarking/test-scenarios/production-simulation","title":"SCENARIO 4: Production Simulation","description":"When to use this scenario:","source":"@site/docs/guidance/benchmarking/4-test-scenarios/4-production-simulation.md","sourceDirName":"guidance/benchmarking/4-test-scenarios","slug":"/guidance/benchmarking/test-scenarios/production-simulation","permalink":"/ai-on-eks/docs/guidance/benchmarking/test-scenarios/production-simulation","draft":false,"unlisted":false,"editUrl":"https://github.com/awslabs/ai-on-eks/blob/main/website/docs/guidance/benchmarking/4-test-scenarios/4-production-simulation.md","tags":[],"version":"current","sidebarPosition":4,"frontMatter":{"sidebar_label":"Scenario 4 - Production Simulation"},"sidebar":"guidance","previous":{"title":"Scenario 3 - Automatic Saturation Detection","permalink":"/ai-on-eks/docs/guidance/benchmarking/test-scenarios/automatic-saturation-detection"},"next":{"title":"Scenario 5 - Real Dataset Testing","permalink":"/ai-on-eks/docs/guidance/benchmarking/test-scenarios/real-dataset-testing"}}');var a=t(74848),s=t(28453);const r={sidebar_label:"Scenario 4 - Production Simulation"},o="SCENARIO 4: Production Simulation",c={},l=[{value:"When to use this scenario:",id:"when-to-use-this-scenario",level:2},{value:"Deployment",id:"deployment",level:2},{value:"Using Helm Chart (Recommended)",id:"using-helm-chart-recommended",level:3},{value:"Customizing Traffic Patterns",id:"customizing-traffic-patterns",level:3},{value:"Key Configuration:",id:"key-configuration",level:2},{value:"Understanding the results:",id:"understanding-the-results",level:2}];function d(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",ul:"ul",...(0,s.R)(),...e.components},{Details:t}=n;return t||function(e,n){throw new Error("Expected "+(n?"component":"object")+" `"+e+"` to be defined: you likely forgot to import, pass, or provide it.")}("Details",!0),(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"scenario-4-production-simulation",children:"SCENARIO 4: Production Simulation"})}),"\n",(0,a.jsx)(n.h2,{id:"when-to-use-this-scenario",children:"When to use this scenario:"}),"\n",(0,a.jsx)(n.p,{children:'Deploy production simulation as your final validation before launch; it replicates real-world traffic chaos with variable request sizes and Poisson (bursty) arrivals instead of uniform load. Use this after optimizing based on baseline and saturation tests to answer "will users have a good experience under realistic conditions?" Real production traffic doesn\'t consist of identical 512-token requests arriving like clockwork; users send varying lengths at random intervals, and this test validates your system handles that heterogeneity while maintaining acceptable percentile latencies for SLA setting.'}),"\n",(0,a.jsx)(n.h2,{id:"deployment",children:"Deployment"}),"\n",(0,a.jsx)(n.h3,{id:"using-helm-chart-recommended",children:"Using Helm Chart (Recommended)"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"# Add the AI on EKS Helm repository\nhelm repo add ai-on-eks https://awslabs.github.io/ai-on-eks-charts/\nhelm repo update\n\n# Install production scenario\nhelm install production-sim ai-on-eks/benchmark-charts \\\n  --set benchmark.scenario=production \\\n  --set benchmark.target.baseUrl=http://qwen3-vllm.default:8000 \\\n  --set benchmark.target.modelName=qwen3-8b \\\n  --set benchmark.target.tokenizerPath=Qwen/Qwen3-8B \\\n  --namespace benchmarking --create-namespace\n\n# Monitor progress - expect variable latency due to bursty traffic\nkubectl logs -n benchmarking -l benchmark.scenario=production -f\n"})}),"\n",(0,a.jsx)(n.h3,{id:"customizing-traffic-patterns",children:"Customizing Traffic Patterns"}),"\n",(0,a.jsx)(n.p,{children:"Adjust burst rate and variability:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-yaml",children:"# custom-production.yaml\nbenchmark:\n  scenario: production\n  target:\n    baseUrl: http://your-model.your-namespace:8000\n  scenarios:\n    production:\n      data:\n        input:\n          mean: 2048          # Longer average prompts\n          stdDev: 1024        # Higher variability\n          min: 256\n          max: 8192\n      load:\n        type: poisson         # Keeps bursty arrivals\n        stages:\n          - rate: 20          # Higher target QPS\n            duration: 900     # Longer test (15 min)\n"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"helm install production-sim ai-on-eks/benchmark-charts -f custom-production.yaml -n benchmarking\n"})}),"\n",(0,a.jsx)(n.h2,{id:"key-configuration",children:"Key Configuration:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Variable synthetic data (Gaussian distributions for input/output)"}),"\n",(0,a.jsx)(n.li,{children:"Wide token distributions (mean 1024/512 with high variance)"}),"\n",(0,a.jsx)(n.li,{children:"Poisson (bursty) arrivals instead of uniform load"}),"\n",(0,a.jsx)(n.li,{children:"Streaming enabled"}),"\n",(0,a.jsx)(n.li,{children:"8 concurrent workers"}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"understanding-the-results",children:"Understanding the results:"}),"\n",(0,a.jsx)(n.p,{children:"Focus exclusively on P99 and P95 latency; these percentiles represent the worst experience that 99% and 95% of users encounter, unlike averages that hide poor tail performance. The wide input/output distributions create natural variability, so expect higher variance than baseline tests; this is normal and reflects production reality. Poisson bursts cause temporary queue buildup even at sustainable average rates, so if P99 is significantly worse than uniform-load testing suggested, you need more headroom than expected. Set SLAs based on these realistic percentiles, not averages; if P99 TTFT is 1200ms, don't promise sub-second latency even though mean might be 400ms."}),"\n",(0,a.jsxs)(t,{children:[(0,a.jsx)("summary",{children:(0,a.jsx)("strong",{children:"Alternative: Raw Kubernetes YAML"})}),(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-yaml",children:'---\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: inference-perf-production\n  namespace: benchmarking\ndata:\n  config.yml: |\n    api:\n      type: completion\n      streaming: true\n\n    data:\n      type: synthetic\n      input_distribution:\n        mean: 1024\n        std_dev: 512\n        min: 128\n        max: 4096\n      output_distribution:\n        mean: 512\n        std_dev: 256\n        min: 50\n        max: 2048\n\n    load:\n      type: poisson  # Realistic bursty arrivals\n      stages:\n        - rate: 15\n          duration: 600\n      num_workers: 8\n\n    server:\n      type: vllm\n      model_name: qwen3-8b\n      base_url: http://qwen3-vllm.default:8000\n      ignore_eos: true\n\n    tokenizer:\n      pretrained_model_name_or_path: Qwen/Qwen3-8B\n\n    storage:\n      simple_storage_service:\n        bucket_name: "inference-perf-results"\n        path: "production-sim/results"\n---\napiVersion: batch/v1\nkind: Job\nmetadata:\n  name: inference-perf-production\n  namespace: benchmarking\nspec:\n  backoffLimit: 2\n  ttlSecondsAfterFinished: 3600\n  template:\n    spec:\n      restartPolicy: Never\n      serviceAccountName: inference-perf-sa\n\n      affinity:\n        podAffinity:\n          requiredDuringSchedulingIgnoredDuringExecution:\n          - labelSelector:\n              matchLabels:\n                app.kubernetes.io/component: qwen3-vllm\n            topologyKey: topology.kubernetes.io/zone\n\n      containers:\n      - name: inference-perf\n        image: quay.io/inference-perf/inference-perf:v0.2.0\n        command: ["/bin/sh", "-c"]\n        args:\n        - |\n          inference-perf --config_file /workspace/config.yml\n        volumeMounts:\n        - name: config\n          mountPath: /workspace/config.yml\n          subPath: config.yml\n        resources:\n          requests:\n            cpu: "2"\n            memory: "4Gi"\n          limits:\n            cpu: "4"\n            memory: "8Gi"\n\n      volumes:\n      - name: config\n        configMap:\n          name: inference-perf-production\n'})})]})]})}function u(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}}}]);