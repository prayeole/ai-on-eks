"use strict";(self.webpackChunkdoeks_website=self.webpackChunkdoeks_website||[]).push([[8506],{28453:(e,n,r)=>{r.d(n,{R:()=>t,x:()=>c});var i=r(96540);const s={},a=i.createContext(s);function t(e){const n=i.useContext(a);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:t(e.components),i.createElement(a.Provider,{value:n},e.children)}},57014:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>o,contentTitle:()=>c,default:()=>l,frontMatter:()=>t,metadata:()=>i,toc:()=>d});const i=JSON.parse('{"id":"guidance/benchmarking/index","title":"Benchmarking Guide (With Inference Perf)","description":"What This Guide Covers","source":"@site/docs/guidance/benchmarking/index.md","sourceDirName":"guidance/benchmarking","slug":"/guidance/benchmarking/","permalink":"/ai-on-eks/docs/guidance/benchmarking/","draft":false,"unlisted":false,"editUrl":"https://github.com/awslabs/ai-on-eks/blob/main/website/docs/guidance/benchmarking/index.md","tags":[],"version":"current","frontMatter":{"sidebar_label":"Benchmarking LLM Inference Performance on Amazon EKS"},"sidebar":"guidance","previous":{"title":"EKS Best Practices","permalink":"/ai-on-eks/docs/guidance/eks-best-practices"},"next":{"title":"Understanding the Benchmark Challenge","permalink":"/ai-on-eks/docs/guidance/benchmarking/understanding-the-benchmark-challenge/"}}');var s=r(74848),a=r(28453);const t={sidebar_label:"Benchmarking LLM Inference Performance on Amazon EKS"},c="Benchmarking Guide (With Inference Perf)",o={},d=[{value:"What This Guide Covers",id:"what-this-guide-covers",level:2}];function h(e){const n={a:"a",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"benchmarking-guide-with-inference-perf",children:"Benchmarking Guide (With Inference Perf)"})}),"\n",(0,s.jsx)(n.h2,{id:"what-this-guide-covers",children:"What This Guide Covers"}),"\n",(0,s.jsx)(n.p,{children:"This guide provides a comprehensive approach to benchmarking LLM inference performance:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.a,{href:"/ai-on-eks/docs/guidance/benchmarking/understanding-the-benchmark-challenge/",children:"Understanding the Benchmark Challenge"})})," - Why LLM benchmarking is complex and what makes it different from traditional AI models"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.a,{href:"/ai-on-eks/docs/guidance/benchmarking/key-metrics-for-benchmarking-llms/",children:"Key Metrics for Benchmarking LLMs"})})," - Essential metrics (TTFT, ITL, TPS) and what they mean for your deployment"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:(0,s.jsx)(n.a,{href:"/ai-on-eks/docs/guidance/benchmarking/benchmarking-with-inference-perf/inference-perf",children:"Benchmarking with Inference Perf"})})," - Using the standardized Inference Perf tool to measure performance"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Test Scenarios"})," - Practical examples for baseline, saturation, production simulation, and real dataset testing"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Resources"})," - Complete deployment examples and reference configurations"]}),"\n"]})]})}function l(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(h,{...e})}):h(e)}}}]);